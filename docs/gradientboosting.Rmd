---
title: "GradientClassificationBoosting"
author: "Jouke Profijt"
date: "29-4-2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = '/Users/jouke/Projects/Analysis metrics/' )
```

```{r echo=FALSE}
library(DBI)
library(knitr)
library(ggplot2)
library(stringr)

prepData <- read.csv2("data/GokuVsVegeta/QXTData.csv", sep = "\t", header = F, dec = ",")
colnames(prepData) <- c("SampleName", "Concentration", "A260_280", "A260_230", "ProcessStepId", "ExitDate", "ContainerPosition", "RequestId", "BatchId", "FinishedBy", "isFirstPriority", "FieldName", "DataType", "Value")
## establish connection to sqlite db
connection = dbConnect(RSQLite::SQLite(), "data/SQLITE/databaseFull.db")
samples <- dbReadTable(connection, "Samples")
dbDisconnect(connection)
samples$DNA_numbers <- as.factor(apply(samples, 1, function(x) {
  ids <- unlist(strsplit(x[1], "_"))
  ids[3]
  }))

samples$DesignNumber <- as.factor(apply(samples, 1, function(x) {
  ids <- unlist(strsplit(x[1], "_"))
  DN <- ids[6]
  if (is.null(DN) | is.na(DN)) {
    return(x["capturingKit"])
  } else {
    return(DN)
  }
  }))

samples <- subset(samples, ((grepl("DNA\\d+", DNA_numbers) )))
head(samples)
levels(samples$UniqueKits)

check_flowcell <- function(row) {
  x <- row["flowcell"]
  if (str_detect(x, regex("C[A-Z,0-9]{4}ANXX$"))) { return("HiSeq 1500")}
  if (str_detect(x, regex("C[A-Z,0-9]{4}ACXX$"))) { return("HiSeq 1000")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}ADXX$"))) { return("HiSeq 1500")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BCXX$"))) { return("HiSeq 1500")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BCXY$"))) { return("HiSeq 1500")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BBXX$"))) { return("HiSeq 4000")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BBXY$"))) { return("HiSeq 4000")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}CCXX$"))) { return("HiSeq X")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}CCXY$"))) { return("HiSeq X")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}ALXX$"))) { return("HiSeq X")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BGXX$"))) { return("NextSeq")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BGXY$"))) { return("NextSeq")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BGX2$"))) { return("NextSeq")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}AFXX$"))) { return("NextSeq")}
  if (str_detect(x, regex("A[A-Z,0-9]{4}$"))) { return("MiSeq")}
  if (str_detect(x, regex("B[A-Z,0-9]{4}$"))) { return("MiSeq")}
  if (str_detect(x, regex("D[A-Z,0-9]{4}$"))) { return("MiSeq")}
  if (str_detect(x, regex("G[A-Z,0-9]{4}$"))) { return("MiSeq")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}DMXX$"))) { return("NovaSeq")}
  return(row["Sequencer"]) # if no instrument type can be found, return the sequencer id to keep it destinguiasable

}
instruments <- function(row) {
  x <- row["Sequencer"]
  flowcell <- row["Flowcell"]
  if (str_detect(x, regex("HWI-M[0-9]{4}$"))) {
   return("MiSeq")
 }
  if (str_detect(x, regex("HWUSI"))) {
   return("Genome Analyzer IIx")
  }
  if (str_detect(x, regex("M[0-9]{5}$"))) {
   return("MiSeq")
  }
  if (str_detect(x, regex("HWI-C[0-9]{5}$"))) {
   return("HiSeq 1500")
  }
  if (str_detect(x, regex("C[0-9]{5}$"))) {
   return("HiSeq 1500")
  }
  if (str_detect(x, regex("HWI-D[0-9]{5}$"))) {
   return("HiSeq 2500")
  }
  if (str_detect(x, regex("D[0-9]{5}$"))) {
   return("HiSeq 2500")
  }
  if (str_detect(x, regex("J[0-9]{5}$"))) {
   return("HiSeq 3000")
  }
  if (str_detect(x, regex("K[0-9]{5}$"))) {
    return(check_flowcell(row))
  }
  if (str_detect(x, regex("E[0-9]{5}$"))) {
   return("HiSeq X")
  }
  if (str_detect(x, regex("NB[0-9]{6}$"))) {
   return("NextSeq")
  }
  if (str_detect(x, regex("NS[0-9]{6}$"))) {
   return("NextSeq")
  }
  if (str_detect(x, regex("MN[0-9]{5}$"))) {
   return("MiniSeq")
  }
  return(check_flowcell(row))
}

samples$Instrument <- apply(samples, 1, instruments)
samples$startDate <- as.Date(samples$startDate)
samples <- samples[order(samples$startDate),]
rm(connection)
head(samples)
```

```{r}
l <- list()
v <- c()
i <- 1
for (DNA_number in samples$DNA_numbers) {
  unique_combo <- paste0(DNA_number, samples$DesignNumber[i])
  if (is.null(l[unique_combo][[1]])) {
    l[unique_combo] <- i
    v <- append(v, "Not Reinserted")
  } else {
    v[l[unique_combo][[1]]] <- "Reinserted"
    v <- append(v, "Not Reinserted")
    l[unique_combo] <- i
  }
  i <- i + 1
}
samples$Used <- as.factor(v)
rm(v, l)
```
```{r}
connection = dbConnect(RSQLite::SQLite(), "data/SQLITE/databaseFull.db")
dbListTables(connection)
dbDisconnect(connection)
```

```{r}
library(dplyr)
connection = dbConnect(RSQLite::SQLite(), "data/SQLITE/databaseFull.db")

ASM <- dbReadTable(connection, "AlignmentSummaryMetrics")
ASM <- ASM[ASM$Category == "PAIR",]
hs <- dbReadTable(connection, "hsMetrics")
InsertSizes <- dbReadTable(connection, "InsertSizes")
RUNS <- dbReadTable(connection, "RUNS")
RunSummary <- dbReadTable(connection, "RunSummary")

Lanes <- dbReadTable(connection, "Lanes")
res <- dbSendQuery(connection, "
                  SELECT
                  Samples.ID as SampleID,
                  avg(Lanes.DensityMAX) as ClusterDensity,
                  avg(Lanes.Q30) as Average_Q30
                  FROM Samples 
                  INNER JOIN RUNS ON Samples.Sequencer==RUNS.Sequencer AND Samples.Run==RUNS.Number AND Samples.startDate==RUNS.Date 
                  INNER JOIN RunSummary ON RUNS.UniqueID==RunSummary.UniqueID
                  INNER JOIN Lanes ON RUNS.UniqueID==Lanes.UniqueID
                  GROUP BY Samples.ID
                  ORDER BY RUNS.Date")
CD <- dbFetch(res)
FL <- dbReadTable(connection, "FlagstatMetrics")
dbDisconnect(connection)
RunSummary <- aggregate(RunSummary[, c(2:4, 6:7)], list(RunSummary$UniqueID), sum)


RunMetrics <- left_join(RUNS, RunSummary, by = c("UniqueID" = "Group.1"))
RunMetrics$Date <- as.Date(RunMetrics$Date)
data <- left_join(RunMetrics, samples, by = c("Sequencer"= "Sequencer", "Number" = "run", "Date" = "startDate"))
data <- left_join(data, CD, by = c("ID" = "SampleID"))
data <- left_join(data, ASM, by = c("ID" = "SampleID"))
data <- left_join(data, hs, by = c("ID" = "SampleID", "RunID.y" = "RunID"))
data <- left_join(data, InsertSizes, by = c("ID" = "SampleID", "RunID.y" = "RunID"))
data <- left_join(data, FL, by = c("ID" = "SampleID", "RunID.y" = "RunID"))

data$Used <- as.factor(data$Used)
str(data)
```

```{r}
data$Instrument <- as.factor(data$Instrument)
data2 <- na.omit(data)
Numeric_data <- subset(data2, select = -c(UniqueID,RunID.x, Number, Instrument,Flowcell, Sequencer, Date, flowcell, project, capturingKit, DNA_numbers, DesignNumber, RunID.y, Category, PairOrientation, ID, BaitSet, Used))
Numeric_data <- as.data.frame(apply(Numeric_data, 2, as.numeric))
variance.data <- apply(Numeric_data, 2, var)
variance.data[variance.data == 0]
```

```{r}
Numeric_data <- subset(Numeric_data, select = -c(PFnoise, PFHQaligned, PFHQalignedQ20Bases, BadCycles, GenomeSize, BaitDesignEfficientcy,  PFBasesAligned, PFUQBasesAligned, OnBaitBases, NearBaitBases, OffBaitBases, OnTargetBases, ExcOverlapPct, AtDropout, GCDropout, TotalFail, SecondaryFail, SupplementaryPass, SupplementaryFail, DuplicateFail, MappedFail, PairedSeqFail, Read1Fail, Read2Fail, ProperPairFail, SelfAndMateFail, SingletonsFail, MateOnDiffChromosomeLowFail, MateOnDiffChromosomeHighFail)) # Remove values with 0 variance, aka not informative
```

```{r}
library(ggplot2)
Not.reinserted <- sum(data2$Used == "Not Reinserted")
Reinserted <- sum(data2$Used == "Reinserted")

df <- as.data.frame(c("Not Reinserted", "Reinserted"))
colnames(df) <- c("action")
df$num <- c(Not.reinserted, Reinserted)

ggplot(data = data2, aes(x=Used)) + geom_bar()
```

```{r}
library(ggplot2)
library(reshape2)
library(dplyr)

s <- subset(Numeric_data, select = c(AdapterPercentage,MedianAbsoluteDeviation, MinSize, StandardDeviation, W10, W20, W30, W40, W50, W60, W70, W80, W90, W99))

corMat <- round(cor(x=Numeric_data, method = "spearman", use = "complete.obs"), 2)



cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ theme(legend.position = "none") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + ggtitle("Correlations between variables")
cor.heatmap
rm(corMat, cor.heatmap, s)
```
```{r}

library(ggplot2)
library(reshape2)
library(dplyr)

s <- subset(Numeric_data, select = c(MeanReadLenght, ReadsAllignedInPairs, MaxSize, ReadPairs, TotalReads.x, PFreads.x, PFaligned, PFuniqueReads, PFHQalignedBases, PFalignedBases, PFmismatchRate, 
      PercentageUsableBasesOnBait, PercentageUsableBasesOnTarget, TotalPass, SecondaryPass, DuplicatePass, MappedPass, 
      PairedSeqPass, Read1Pass, Read2Pass, PoperPairPass, SelfAndMatePass, SingletonsPass, SingletonsPercentage, MateOnDiffChromosomeLowPass, MateOnDiffChromosomeHighPass))
corMat <- round(cor(y=Numeric_data, x=s, method = "spearman", use = "complete.obs"), 2)



cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ theme(legend.position = "none") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + ggtitle("Correlations between variables")
cor.heatmap
rm(corMat, cor.heatmap, s)
```

These metrics are related to the total number of reads.

```{r}

library(ggplot2)
library(reshape2)
library(dplyr)

s <- subset(Numeric_data, select = c(PFmismatchRate, PFHQErrorRate))
corMat <- round(cor(y=Numeric_data, x=s, method = "spearman", use = "complete.obs"), 2)



cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ theme(legend.position = "none") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + ggtitle("Correlations between variables")
cor.heatmap
rm(corMat, cor.heatmap, s)
```

```{r}

library(ggplot2)
library(reshape2)
library(dplyr)

s <- subset(Numeric_data, select = c(StrandBalance, MedianSize, MeanSize))
corMat <- round(cor(y=Numeric_data, x=s, method = "spearman", use = "complete.obs"), 2)



cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ theme(legend.position = "none") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + ggtitle("Correlations between variables")
cor.heatmap
rm(corMat, cor.heatmap, s)
```
```{r}

library(ggplot2)
library(reshape2)
library(dplyr)

s <- subset(Numeric_data, select = c(PFHQmedianMismatches, PFindelRate, ChimerasPercentage, MeanBaitCoverage, MeanTargetCoverage, MedianTargetCoverage, FoldEnrichment, TargetBasesPct20X))
corMat <- round(cor(y=Numeric_data, x=s, method = "spearman", use = "complete.obs"), 2)



cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ theme(legend.position = "none") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + ggtitle("Correlations between variables")
cor.heatmap
rm(corMat, cor.heatmap, s)
```

```{r}
Numeric_data$Used <- data2$Used
Numeric_data$kit <- data2$DesignNumber
Numeric_data <- as.data.frame(Numeric_data)
Numeric_data <- subset(Numeric_data, select = -c(AdapterPercentage,MedianAbsoluteDeviation, MinSize, W10, W20, W30, W40, W50, W60, W70, W80, W90, W99))
Numeric_data <- subset(Numeric_data, select = -c(MeanReadLenght, ReadsAllignedInPairs, MaxSize, ReadPairs, PFreads.x, PFaligned, PFuniqueReads, PFHQalignedBases, PFalignedBases, PFmismatchRate, 
      PercentageUsableBasesOnBait, PercentageUsableBasesOnTarget, TotalPass, SecondaryPass, DuplicatePass, MappedPass, 
      PairedSeqPass, Read1Pass, Read2Pass, PoperPairPass, SelfAndMatePass, SingletonsPass, SingletonsPercentage, MateOnDiffChromosomeLowPass, MateOnDiffChromosomeHighPass, PFHQErrorRate))

Numeric_data <- subset(Numeric_data, select = -c(MeanSize, MeanTargetCoverage, FoldEnrichment))
Unlabeled <- subset(Numeric_data, select = -c(Used, kit))

head(Numeric_data)
```

```{r}
library(tidyverse)
library(caret)
library(xgboost)
Numeric_data$Instrument <- data2$Instrument
Numeric_data_u <-Numeric_data


training.data <- Numeric_data_u$Used %>% 
  createDataPartition(p = 0.8, list = FALSE)
set.seed(123)
train.data  <- Numeric_data_u[training.data, ]
test.data <- Numeric_data_u[-training.data, ]
```

```{r}
# Fit the model on the training set
set.seed(123)
model <- train(
  Used ~., data = train.data, method = "xgbTree",
  trControl = trainControl("cv", number = 10)
  )
# Best tuning parameter
model$bestTune
```

```{r}
predicted.classes <- model %>% predict(test.data)
```
```{r}
mean(predicted.classes == test.data$Used)
test.data$predicted <- predicted.classes

table(test.data$Used, test.data$predicted)
```

```{r}
varImp(model)
```
Standard Deviation: SD of insert sizes over the core of the distribution

Intensity: The average of the A channel, measured at Cycle one of sequencing, averaged over the clusters

PFUQaligned: The number of reads that were aligned to the reference sequence with a mapping quality of Q20 or higher

ChimerasPercentage: Sequences formed from two or more biological sequences joined together, contamination of samples? Fraction of reads that map outside of the maximum insertsize, or have two ends mapping to different chromosomes.

Q30: The percentage of reads that have a quality score of 30 or higher

TotalREads: total number of reads in the run\

StrandBalance: The number of PF reads aligned to the positive strand of the genome divided by the number of PF reads aligned to the genome.

TargetBasespct10X: The fraction of all target bases achieving 10X or greater coverage.

HsLibrarySize: The estimated number of unique molecules in the selected part of the library.

SelectedBasesPercentage: The fraction of Aligend Bases located on or near a baited regio

```{r}
library(ROCR)
a<- as.numeric(test.data$predicted)

b<- as.numeric(test.data$Used)

pred <- prediction(a, b)
auc.tmp <- performance(pred,"auc")
auc <- as.numeric(auc.tmp@y.values)
auc
```
```{r}
head(prepData)
```
```{r}
# Remove unusable columns
prepData <- subset(prepData, select = -c(ExitDate, RequestId, FinishedBy, isFirstPriority))
head(prepData)
```
```{r}
library(plyr)
filtered <- prepData[grepl("DNA-\\d+", prepData$SampleName),]

filtered$SampleName[1] <- "DNA-000557"

uniqueSamples <- as.vector(unique(filtered$SampleName))

getDNAdata <- function(filtered, DNA.Number) {
  DNA.data <- filtered[filtered$SampleName == DNA.Number,]
  colname <- c("DNA_number")
  vals <- c(DNA.Number)
  for (row in 1:nrow(DNA.data)) {
    current <- DNA.data[row,]
    step <- as.character(current$ProcessStepId)
    Field <- as.character(current$FieldName)
    Value <- as.character(current$Value)
    newField <- paste(Field, step, sep = "_")
    colname <- c(colname, Field)
    vals <- c(vals, Value)
  }
  df <- t(data.frame(vals))
  colnames(df) <- colname
  df <- as.data.frame(df)
  return(df)
}
start <- getDNAdata(filtered, uniqueSamples[1])

for (DNANumber in uniqueSamples[-1]) {
  dnadata <- getDNAdata(filtered, DNANumber)
  start <- rbind.fill(start, dnadata)
}

head(start)
convertedPrepData <- as.data.frame(start)
```

```{r}
filtered$Concentration <- as.numeric(gsub(",", ".", filtered$Concentration))
filtered$A260_280 <- as.numeric(gsub(",", ".", filtered$A260_280))
filtered$A260_230 <- as.numeric(gsub(",", ".", filtered$A260_230))
DNA.Numbers <- unique(filtered[1:4])

DNA.Numbers[duplicated(DNA.Numbers$SampleName),]
UniqueDNA <- DNA.Numbers

UniqueDNA$SampleName <- apply(UniqueDNA, 1, function(x) {
  return(gsub('-', '', x["SampleName"]))
})
convertedPrepData$DNA_number <- apply(convertedPrepData, 1, function(x) {
  return(gsub('-', '', x["DNA_number"]))
})
head(UniqueDNA)
```
```{r}
library(ggplot2)
library(dplyr)
data2$DNA_numbers <- as.vector(data2$DNA_numbers)
head(data2)
data2$FractionDuplicate <- (data2$PFreads.y - data2$PFuniqueReads)/data2$PFreads.y
metricsToAnalyze <- subset(data2, select = c(DNA_numbers, Instrument, Average_Q30, ChimerasPercentage, TargetBasesPct10X, HsLibrarySize, OnBaitVSselected, ClusterDensity, FractionDuplicate, Intensity, MedianSize, Date, Used))

preprepData <- inner_join(UniqueDNA, convertedPrepData , by=c("SampleName" = "DNA_number"))
preprepData <- inner_join(preprepData, metricsToAnalyze, by=c("SampleName" = "DNA_numbers"))


```
```{r}
preprepData.sub <- subset(preprepData, select = c(SampleName, Date, Used, Instrument))
preprepData.num <- subset(preprepData, select = c(A260_230, A260_280, Average_Q30, ChimerasPercentage, TargetBasesPct10X, HsLibrarySize, ClusterDensity, FractionDuplicate, Intensity, MedianSize, SampleName))

replaceComma <- function(x) {
  return(gsub(",", ".", x))
}

preprepData.num[-11] <- apply(preprepData.num[-11], 2, replaceComma)
preprepData.num[-11] <- as.data.frame(apply(preprepData.num[-11], 2, as.numeric))

preprepData.tot <- merge(preprepData.sub, preprepData.num, by = c("SampleName" = "SampleName"))
preprepData.tot.na <- na.omit(preprepData.tot)
preprepData.tot.na
```
```{r}

library(ggplot2)
library(reshape2)
library(dplyr)


corMat <- round(cor(preprepData.tot.na[-c(1, 2, 3, 4)], method = "pearson", use = "complete.obs"), 2)



cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ theme(legend.position = "none") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + ggtitle("Correlations between variables")
cor.heatmap
rm(corMat, cor.heatmap, s)
```
```{r}
plot(density(preprepData.tot.na$A260_280), xlab = "A260/280 ratio", main = "Density plot of A260/280 ratio")
```
Company policy states the A260/280 ratio cannot fall below 1.8, or exceed 2.0



```{r}
## H0: Q30 Is not liniarly correlated to the DNA purity (A260_230)
## Ha: Q30 has a correlation to DNA purity (A260_230)
library(ggplot2)
library(Hmisc)
head(preprepData.tot.na)
dat <- preprepData.tot.na[c("Average_Q30", "A260_230", "Instrument", "Used", "Date")]
head(dat)

p1 <- ggplot(dat, aes(x=A260_230, y=Average_Q30, colour = Instrument)) + geom_point() + theme(axis.title.x = element_blank())
p2 <- ggplot(dat, aes(x=A260_230, y=Average_Q30, colour = Used)) + geom_point() + theme(axis.title.x = element_blank())
p3 <- ggplot(dat, aes(y=A260_230, x=Date, colour = Used)) + geom_point() + theme(axis.title.x = element_blank())
p4 <- ggplot(dat, aes(y=Average_Q30, x=Date, colour = Used)) + geom_point() + theme(axis.title.x = element_blank())
c <- rcorr(dat$Average_Q30, dat$A260_230)
pVal <- c$P[1,2]
r <- c$r[1,2]
paste("r: ", r)
paste("Significance: ", pVal)
p1
p2
p3
p4
```
We cannot significantly exclude the possibility of a linear correlation between Q30 and 260_230.
What we do see is a difference between the sequencers, MiSeq seems a lot more consistent between its quality than NextSeq.
The Q30 percentage does not seem to affect wheter or not a sample had to be reinserted or not.
The Q30 percentage seems to have greater fluctuation and outliers in 2018

```{r}
## H0: Q30 Is not liniarly correlated to the DNA purity (A260_280)
## Ha: Q30 has a correlation to DNA purity (A260_280)
library(ggplot2)
library(Hmisc)
dat <- preprepData.tot.na[c("Average_Q30", "A260_280", "Instrument", "Used", "Date")]


p5 <- ggplot(dat, aes(y=A260_280, x=Average_Q30, colour = Instrument)) + geom_point() + theme(axis.title.x = element_blank())
p6 <- ggplot(dat, aes(y=A260_280, x=Average_Q30, colour = Used)) + geom_point() + theme(axis.title.x = element_blank())
p7 <- ggplot(dat, aes(y=A260_280, x=Date, colour = Used)) + geom_point() + theme(axis.title.x = element_blank())

p5
p6
p7
```
```{r}
dat <- preprepData.tot.na[c("Average_Q30", "A260_280", "Instrument", "Used", "Date")]
summaryObj <- summary(dat$A260_280)
QR1 <- summaryObj[2]
QR3 <- summaryObj[5]
dat <- dat[dat$A260_280 > 1,]
dat <- dat[dat$A260_280 < 2.2,]

summaryObj <- summary(dat$Average_Q30)
QR1 <- summaryObj[2]
QR3 <- summaryObj[5]
QR1
dat <- dat[dat$Average_Q30 < QR3,]
dat <- dat[dat$Average_Q30 > QR1,]
ggplot(dat, aes(y=A260_280, x=Average_Q30, colour = Instrument)) + geom_point() + ggtitle("260/280 ratio vs Average Q30 per lane")
c <- rcorr(dat$Average_Q30, dat$A260_280)
pVal <- c$P[1,2]
r <- c$r[1,2]
paste("r: ", r)
paste("Significance: ", pVal)
```

```{r}
library(ggplot2)
library(Hmisc)
dat <- preprepData.tot.na[c("ChimerasPercentage", "A260_280", "Used", "Instrument", "Date")]

dat <- dat[dat$A260_280 > 1,]
dat <- dat[dat$A260_280 < 2.2,]
p2 <- ggplot(dat, aes(x=A260_280, y=ChimerasPercentage, colour = Used)) + geom_point()+ theme(axis.title.x = element_blank())
p3 <- ggplot(dat, aes(x=A260_280, y=ChimerasPercentage, colour = Instrument)) + geom_point()+ theme(axis.title.x = element_blank())
p4 <- ggplot(dat, aes(x=Date, y=ChimerasPercentage, colour = Instrument)) + geom_point()+ theme(axis.title.x = element_blank())
c <- rcorr(dat$ChimerasPercentage, dat$A260_280)
pVal <- c$P[1,2]
r <- c$r[1,2]
paste("r: ", r)
paste("Significance: ", pVal)
p2
p3
p4
```
```{r}
library(ggplot2)
library(Hmisc)
dat <- preprepData.tot.na[c("TargetBasesPct10X", "A260_280", "Used", "Instrument")]
head(dat)
dat <- dat[dat$A260_280 > 1,]

p3 <- ggplot(dat, aes(x=A260_280, y=TargetBasesPct10X, colour = Used)) + geom_point()+ theme(axis.title.x = element_blank())
p4 <- ggplot(dat, aes(x=A260_280, y=TargetBasesPct10X, colour = Instrument)) + geom_point()+ theme(axis.title.x = element_blank())
c <- rcorr(dat$TargetBasesPct10X, dat$A260_280)
pVal <- c$P[1,2]
r <- c$r[1,2]
paste("r: ", r)
paste("Significance: ", pVal)
p3
p4
```

```{r}
library(ggplot2)
library(Hmisc)
dat <- preprepData.tot.na[c("Intensity", "A260_280", "Instrument")]
head(dat)
dat <- dat[dat$A260_280 > 1,]
p4 <- ggplot(dat, aes(x=A260_280, y=Intensity, colour = Instrument)) + geom_point()+ theme(axis.title.x = element_blank())

c <- rcorr(dat$Intensity, dat$A260_280)
pVal <- c$P[1,2]
r <- c$r[1,2]
paste("r: ", r)
paste("Significance: ", pVal)
p4
```
Here we see a clear difference between the sequencer type used.

```{r}
dat.mi <- dat[dat$Instrument == "MiSeq",]
dat.mi <- dat.mi[dat.mi$Intensity < 7500,]
c <- rcorr(dat.mi$Intensity, dat.mi$A260_280)
pVal <- c$P[1,2]
r <- c$r[1,2]
paste("r: ", r)
paste("Significance: ", pVal)
ggplot(dat.mi, aes(x=A260_280, y=Intensity, colour = Instrument)) + geom_point()+ theme(axis.title.x = element_blank())
```
```{r}
dat.out <- dat[(dat$A260_280 > 2.0) | (dat$A260_280 < 1.8),]
ggplot(dat.out, aes(x=A260_280, y=Intensity, colour = Instrument)) + geom_point()+ theme(axis.title.x = element_blank())
```

```{r}
library(ggplot2)
library(Hmisc)
dat <- preprepData.tot.na[c("MedianSize", "A260_280")]
head(dat)
dat <- dat[dat$A260_280 > 1,]
p6 <- ggplot(dat, aes(x=A260_280, y=MedianSize)) + geom_point()+ theme(axis.title.x = element_blank())

c <- rcorr(dat$MedianSize, dat$A260_280)
pVal <- c$P[1,2]
r <- c$r[1,2]
paste("r: ", r)
paste("Significance: ", pVal)
```

```{r}
library(ggplot2)
library(Hmisc)
dat <- preprepData.tot.na[c("FractionDuplicate", "A260_280")]
head(dat)
dat <- dat[dat$A260_280 > 1,]
p7 <- ggplot(dat, aes(x=A260_280, y=FractionDuplicate)) + geom_point()+ theme(axis.title.x = element_blank())

c <- rcorr(dat$FractionDuplicate, dat$A260_280)
pVal <- c$P[1,2]
r <- c$r[1,2]
paste("r: ", r)
paste("Significance: ", pVal)
```

```{r}
library(ggplot2)
library(Hmisc)
dat <- preprepData.tot.na[c("ClusterDensity", "A260_280")]
head(dat)
dat <- dat[dat$A260_280 > 1,]
p8 <- ggplot(dat, aes(x=A260_280, y=ClusterDensity)) + geom_point()+ theme(axis.title.x = element_blank())

c <- rcorr(dat$ClusterDensity, dat$A260_280)
pVal <- c$P[1,2]
r <- c$r[1,2]
paste("r: ", r)
paste("Significance: ", pVal)
```

```{r}
library(ggplot2)
library(Hmisc)
dat <- preprepData.tot.na[c("OnBaitVSselected", "A260_280")]
head(dat)
dat <- dat[dat$A260_280 > 1,]
p9 <- ggplot(dat, aes(x=A260_280, y=OnBaitVSselected)) + geom_point()+ theme(axis.title.x = element_blank())

c <- rcorr(dat$OnBaitVSselected, dat$A260_280)
pVal <- c$P[1,2]
r <- c$r[1,2]
paste("r: ", r)
paste("Significance: ", pVal)
```
From comparing DNA purity to the metrics i do not see any concrete pattern
```{r}
library(gridExtra)
g <-grid.arrange(
  p1,
  p2,
  p3,
  p4,
  p6,
  p7,
  p8,
  p9,
  nrow = 3,
  top = "Metrics compared to DNA purity (A260/280 ratio)"
)
ggsave(
  "DNA-purity.png",
  plot = g
)
```

```{r}
library(ggplot2)
library(Hmisc)
head(preprepData)
dat <- preprepData[c("Date", "Q30")]
head(dat)
p9 <- ggplot(dat, aes(y=Q30, x=Date)) + geom_point()+ theme(axis.title.x = element_blank())


p9
```
# DNA purity A260/230

```{r}
library(ggplot2)
library(Hmisc)
dat <- preprepData.tot.na[c("Q30", "A260_230")]
head(dat)

ggplot(dat, aes(x=A260_230, y=Q30)) + geom_point()

c <- rcorr(dat$Q30, dat$A260_230)
pVal <- c$P[1,2]
r <- c$r[1,2]
paste("r: ", r)
paste("Significance: ", pVal)
```

```{r}
library(ggplot2)
library(Hmisc)
dat <- preprepData.tot.na[c("Q30", "ClusterDensity")]
head(dat)

ggplot(dat, aes(x=ClusterDensity, y=Q30)) + geom_point()

c <- rcorr(dat$Q30, dat$ClusterDensity)
pVal <- c$P[1,2]
r <- c$r[1,2]
paste("r: ", r)
paste("Significance: ", pVal)
```
```{r}
scatter.smooth(x=dat.g1$A260_280, y=dat.g1$Q30, main="Dist ~ Speed")  
linearMod <- lm(A260_280 ~ Q30, data=dat.g1)
ModelSummary <- summary(linearMod)
ModelCoefficents <- ModelSummary$coefficients
beta.estimate <- ModelCoefficents["Q30", "Estimate"]  # get beta estimate for speed
std.error <- ModelCoefficents["Q30", "Std. Error"]
t_value <- beta.estimate/std.error
p_value <- 2*pt(-abs(t_value), df=nrow(dat.g1)-ncol(dat.g1))
f_statistic <- linearMod$fstatistic[1]
f <- summary(linearMod)$fstatistic
model_p <- pf(f[1], f[2], f[3], lower=FALSE)
paste("T-value:", t_value)
paste("P-value:", p_value)
paste("Model F statistic:", f)
paste("Model P-value:", model_p)
```

```{r}
## H0: Q30 Is not correlated to the DNA purity (A260_280)
## Ha: Q30 has a correlation to DNA purity (A260_280)

#Means
Q30M <- mean(dat.g1$Q30)
PurityM <- mean(dat.g1$A260_280)

#Deviation Scores
deQ30 <- dat.g1$Q30 - Q30M
dePurity <- dat.g1$A260_280 - PurityM

deQ302 <- deQ30 ^2
dePurity2 <- dePurity ^2

ssQ30 <- sum(deQ302)
ssPurity <- sum(dePurity2)

#Sum of Products
SP <- sum(deQ30 * dePurity)

r <- SP/(sqrt(ssQ30) * sqrt(ssPurity))
r
```
Whith a significance

```{r}
library(ggplot2)
dat <- preprepData.num.na[c("Q30", "MOLARITY")]

ggplot(dat, aes(x=MOLARITY, y=Q30)) + geom_point()

## H0: Q30 Is not correlated to the DNA purity (A260_280)
## Ha: Q30 has a correlation to DNA purity (A260_280)

#Means
Q30M <- mean(dat$Q30)
PurityM <- mean(dat$A260_280)

#Deviation Scores
deQ30 <- dat$Q30 - Q30M
dePurity <- dat$A260_280 - PurityM

deQ302 <- deQ30 ^2
dePurity2 <- dePurity ^2

ssQ30 <- sum(deQ302)
ssPurity <- sum(dePurity2)

#Sum of Products
SP <- sum(deQ30 * dePurity)

r <- SP/(sqrt(ssQ30) * sqrt(ssPurity))
r
```


```{r}
ggplot(preprepData.num.na, aes(x=Concentration, y=TargetBasesPct10X)) + geom_point()
ggplot(preprepData.num.na, aes(x=A260_280, y=TargetBasesPct10X)) + geom_point()
ggplot(preprepData.num.na, aes(x=A260_230, y=TargetBasesPct10X)) + geom_point()
ggplot(preprepData.num.na, aes(x=CONCENTRATION, y=TargetBasesPct10X)) + geom_point()
ggplot(preprepData.num.na, aes(x=MOLARITY, y=TargetBasesPct10X)) + geom_point()
ggplot(preprepData.tot2, aes(x=SURESELECT_QXT_KIT_ID, y=TargetBasesPct10X)) + geom_point()
ggplot(preprepData.tot2, aes(x=SURESELECT_QXT_HYB_MOD_BOX1_ID, y=TargetBasesPct10X)) + geom_point()
ggplot(preprepData.tot2, aes(x=ROBOTCONTROLE_USER, y=TargetBasesPct10X)) + geom_boxplot()
ggplot(preprepData.tot2, aes(x=AMPUREBEADS_ID, y=TargetBasesPct10X)) + geom_point()
ggplot(preprepData.tot2, aes(x=ETOH_ID, y=TargetBasesPct10X)) + geom_point()
ggplot(preprepData.tot2, aes(x=SURESELECT_TARGET_ENRICHMENT_KIT, y=TargetBasesPct10X)) + geom_point()
```
```{r}
ggplot(preprepData.num.na, aes(x=Concentration, y=HsLibrarySize)) + geom_point()
ggplot(preprepData.num.na, aes(x=A260_280, y=HsLibrarySize)) + geom_point()
ggplot(preprepData.num.na, aes(x=A260_230, y=HsLibrarySize)) + geom_point()
ggplot(preprepData.num.na, aes(x=CONCENTRATION, y=HsLibrarySize)) + geom_point()
ggplot(preprepData.num.na, aes(x=MOLARITY, y=HsLibrarySize)) + geom_point()
ggplot(preprepData.tot2, aes(x=SURESELECT_QXT_KIT_ID, y=HsLibrarySize)) + geom_point()
ggplot(preprepData.tot2, aes(x=SURESELECT_QXT_HYB_MOD_BOX1_ID, y=HsLibrarySize)) + geom_point()
ggplot(preprepData.tot2, aes(x=ROBOTCONTROLE_USER, y=HsLibrarySize)) + geom_boxplot()
ggplot(preprepData.tot2, aes(x=AMPUREBEADS_ID, y=HsLibrarySize)) + geom_point()
ggplot(preprepData.tot2, aes(x=ETOH_ID, y=HsLibrarySize)) + geom_point()
ggplot(preprepData.tot2, aes(x=SURESELECT_TARGET_ENRICHMENT_KIT, y=HsLibrarySize)) + geom_point()
```
```{r}
ggplot(preprepData.num.na, aes(x=Concentration, y=OnBaitVSselected)) + geom_point()
ggplot(preprepData.num.na, aes(x=A260_280, y=OnBaitVSselected)) + geom_point()
ggplot(preprepData.num.na, aes(x=A260_230, y=OnBaitVSselected)) + geom_point()
ggplot(preprepData.num.na, aes(x=CONCENTRATION, y=OnBaitVSselected)) + geom_point()
ggplot(preprepData.num.na, aes(x=MOLARITY, y=OnBaitVSselected)) + geom_point()
ggplot(preprepData.tot2, aes(x=SURESELECT_QXT_KIT_ID, y=OnBaitVSselected)) + geom_point()
ggplot(preprepData.tot2, aes(x=SURESELECT_QXT_HYB_MOD_BOX1_ID, y=OnBaitVSselected)) + geom_point()
ggplot(preprepData.tot2, aes(x=ROBOTCONTROLE_USER, y=OnBaitVSselected)) + geom_boxplot()
ggplot(preprepData.tot2, aes(x=AMPUREBEADS_ID, y=OnBaitVSselected)) + geom_point()
ggplot(preprepData.tot2, aes(x=ETOH_ID, y=OnBaitVSselected)) + geom_point()
ggplot(preprepData.tot2, aes(x=SURESELECT_TARGET_ENRICHMENT_KIT, y=OnBaitVSselected)) + geom_point()
```

```{r}
ggplot(preprepData.num.na, aes(x=Concentration, y=ClusterDensity)) + geom_point()
ggplot(preprepData.num.na, aes(x=A260_280, y=ClusterDensity)) + geom_point()
ggplot(preprepData.num.na, aes(x=A260_230, y=ClusterDensity)) + geom_point()
ggplot(preprepData.num.na, aes(x=CONCENTRATION, y=ClusterDensity)) + geom_point()
ggplot(preprepData.num.na, aes(x=MOLARITY, y=ClusterDensity)) + geom_point()
ggplot(preprepData.tot2, aes(x=SURESELECT_QXT_KIT_ID, y=ClusterDensity)) + geom_point()
ggplot(preprepData.tot2, aes(x=SURESELECT_QXT_HYB_MOD_BOX1_ID, y=ClusterDensity)) + geom_point()
ggplot(preprepData.tot2, aes(x=ROBOTCONTROLE_USER, y=ClusterDensity)) + geom_boxplot()
ggplot(preprepData.tot2, aes(x=AMPUREBEADS_ID, y=ClusterDensity)) + geom_point()
ggplot(preprepData.tot2, aes(x=ETOH_ID, y=ClusterDensity)) + geom_point()
ggplot(preprepData.tot2, aes(x=SURESELECT_TARGET_ENRICHMENT_KIT, y=ClusterDensity)) + geom_point()
```
```{r}
ggplot(preprepData.num.na, aes(x=Concentration, y=FractionDuplicate)) + geom_point()
ggplot(preprepData.num.na, aes(x=A260_280, y=FractionDuplicate)) + geom_point()
ggplot(preprepData.num.na, aes(x=A260_230, y=FractionDuplicate)) + geom_point()
ggplot(preprepData.num.na, aes(x=CONCENTRATION, y=FractionDuplicate)) + geom_point()
ggplot(preprepData.num.na, aes(x=MOLARITY, y=FractionDuplicate)) + geom_point()
ggplot(preprepData.tot2, aes(x=SURESELECT_QXT_KIT_ID, y=FractionDuplicate)) + geom_point()
ggplot(preprepData.tot2, aes(x=SURESELECT_QXT_HYB_MOD_BOX1_ID, y=FractionDuplicate)) + geom_point()
ggplot(preprepData.tot2, aes(x=ROBOTCONTROLE_USER, y=FractionDuplicate)) + geom_boxplot()
ggplot(preprepData.tot2, aes(x=AMPUREBEADS_ID, y=FractionDuplicate)) + geom_point()
ggplot(preprepData.tot2, aes(x=ETOH_ID, y=FractionDuplicate)) + geom_point()
ggplot(preprepData.tot2, aes(x=SURESELECT_TARGET_ENRICHMENT_KIT, y=FractionDuplicate)) + geom_point()
```
```{r}
ggplot(preprepData.num.na, aes(x=Concentration, y=Intensity)) + geom_point()
ggplot(preprepData.num.na, aes(x=A260_280, y=Intensity)) + geom_point()
ggplot(preprepData.num.na, aes(x=A260_230, y=Intensity)) + geom_point()
ggplot(preprepData.num.na, aes(x=CONCENTRATION, y=Intensity)) + geom_point()
ggplot(preprepData.num.na, aes(x=MOLARITY, y=Intensity)) + geom_point()
ggplot(preprepData.tot2, aes(x=SURESELECT_QXT_KIT_ID, y=Intensity)) + geom_point()
ggplot(preprepData.tot2, aes(x=SURESELECT_QXT_HYB_MOD_BOX1_ID, y=Intensity)) + geom_point()
ggplot(preprepData.tot2, aes(x=ROBOTCONTROLE_USER, y=Intensity)) + geom_boxplot()
ggplot(preprepData.tot2, aes(x=AMPUREBEADS_ID, y=Intensity)) + geom_point()
ggplot(preprepData.tot2, aes(x=ETOH_ID, y=Intensity)) + geom_point()
ggplot(preprepData.tot2, aes(x=SURESELECT_TARGET_ENRICHMENT_KIT, y=Intensity)) + geom_point()
```

```{r}
ggplot(preprepData.num.na, aes(x=Concentration, y=MedianSize)) + geom_point()
ggplot(preprepData.num.na, aes(x=A260_280, y=MedianSize)) + geom_point()
ggplot(preprepData.num.na, aes(x=A260_230, y=MedianSize)) + geom_point()
ggplot(preprepData.num.na, aes(x=CONCENTRATION, y=MedianSize)) + geom_point()
ggplot(preprepData.num.na, aes(x=MOLARITY, y=MedianSize)) + geom_point()
ggplot(preprepData.tot2, aes(x=SURESELECT_QXT_KIT_ID, y=MedianSize)) + geom_point()
ggplot(preprepData.tot2, aes(x=SURESELECT_QXT_HYB_MOD_BOX1_ID, y=MedianSize)) + geom_point()
ggplot(preprepData.tot2, aes(x=ROBOTCONTROLE_USER, y=MedianSize)) + geom_boxplot()
ggplot(preprepData.tot2, aes(x=AMPUREBEADS_ID, y=MedianSize)) + geom_point()
ggplot(preprepData.tot2, aes(x=ETOH_ID, y=MedianSize)) + geom_point()
ggplot(preprepData.tot2, aes(x=SURESELECT_TARGET_ENRICHMENT_KIT, y=MedianSize)) + geom_point()
```

```{r}
ggplot(preprepData, aes(x=Concentration, y=Q30)) + geom_point()
ggplot(preprepData, aes(x=A260_280, y=Q30)) + geom_point()
ggplot(preprepData, aes(x=A260_230, y=Q30)) + geom_point()
```
```{r}
ggplot(preprepData, aes(x=Concentration, y=TargetBasesPct10X)) + geom_point()
ggplot(preprepData, aes(x=A260_280, y=TargetBasesPct10X)) + geom_point()
ggplot(preprepData, aes(x=A260_230, y=TargetBasesPct10X)) + geom_point()
```

```{r}
library(factoextra)
library(ggfortify)

res.pca <- prcomp(Unlabeled, scale = TRUE)
fviz_eig(res.pca)
```

```{r}
autoplot(res.pca, data = Numeric_data, colour = "Used")
```

```{r}
library(caret)
 
preproc1 <- preProcess(subset(Numeric_data, select = -c(Used, kit)), method=c("center", "scale"))
 
norm1 <- predict(preproc1, subset(Numeric_data, select = -c(Used, kit)))
```


```{r}
library(tidyverse)
library(caret)
library(xgboost)
normU <- norm1
normU$Used <- Numeric_data$Used


training.data2 <- normU$Used %>% 
  createDataPartition(p = 0.8, list = FALSE)
set.seed(123)
train.data2  <- normU[training.data2, ]
test.data2 <- normU[-training.data2, ]
```

```{r}
# Fit the model on the training set
set.seed(123)
model2 <- train(
  Used ~., data = train.data2, method = "xgbTree",
  trControl = trainControl("cv", number = 10)
  )
# Best tuning parameter
model2$bestTune
```

```{r}
predicted.classes <- model2 %>% predict(test.data2)
mean(predicted.classes == test.data2$Used)
```

```{r}
varImp(model2)
```

Chimeras Percentage, Interesting. Chimeras can be seen as contamination of samples/reads. As this metric seems to contri

```{r}
library(ROCR)
a<- as.numeric(predicted.classes)

b<- as.numeric(test.data2$Used)

pred <- prediction(a, b)
auc.tmp <- performance(pred,"auc")
auc <- as.numeric(auc.tmp@y.values)
auc
```
```{r}
summary(Numeric_data$ChimerasPercentage)
```

```{r}
library(tidyverse)
library(caret)
library(xgboost)
normKits <- norm1
normKits$Kit <- droplevels(Numeric_data_0$kit)
levels(Numeric_data_0$kit)

training.data3 <- normKits$Kit %>% 
  createDataPartition(p = 0.8, list = FALSE)
set.seed(123)
train.data3  <- normKits[training.data3, ]
test.data3 <- normKits[-training.data3, ]
```


```{r}
library(tidyverse)
library(caret)
library(xgboost)
# Split the data into training and test set
coverage_prediction_data <- subset(Numeric_data, select = -c(TargetBasesPct10X, TargetBasesPct30X, TargetBasesPct40X, TargetBasesPct50X, TargetBasesPct100X, TargetBasesPct1X, TargetBasesPct2X, MeanTargetCoverage, MedianTargetCoverage))
set.seed(123)
training.samples4 <- Numeric_data$TargetBasesPct20X %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data4  <- Numeric_data[training.samples4, ]
test.data4 <- Numeric_data[-training.samples4, ]
```

```{r}
# Fit the model on the training set
set.seed(123)
model4 <- train(
  TargetBasesPct20X ~., data = train.data4, method = "xgbTree",
  trControl = trainControl("cv", number = 10)
  )
# Best tuning parameter mtry
model4$bestTune
# Make predictions on the test data
predictions4 <- model4 %>% predict(test.data4)
head(predictions4)
# Compute the average prediction error RMSE
RMSE(predictions4, test.data4$TargetBasesPct20X)
```

```{r}
varImp(model4)
```

```{r}
training.samples5 <- coverage_prediction_data$TargetBasesPct20X %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data5  <- coverage_prediction_data[training.samples5, ]
test.data5 <- coverage_prediction_data[-training.samples5, ]
```

```{r}
# Fit the model on the training set
set.seed(123)
model5 <- train(
  TargetBasesPct20X ~., data = train.data5, method = "xgbTree",
  trControl = trainControl("cv", number = 10)
  )
# Best tuning parameter mtry
model5$bestTune
# Make predictions on the test data
predictions5 <- model5 %>% predict(test.data5)
head(predictions5)
# Compute the average prediction error RMSE
RMSE(predictions5, test.data5$TargetBasesPct20X)
varImp(model5)
max()
```

```{r}
q30_data <- subset(Numeric_data, select = -c(W99, W90, W80, W70, W60, W50, W40, W30, W20, W10))
training.samples6 <- q30_data$Q30 %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data6  <- q30_data[training.samples6, ]
test.data6 <- q30_data[-training.samples6, ]
```

```{r}
# Fit the model on the training set
set.seed(123)
model6 <- train(
  Q30 ~., data = train.data6, method = "xgbTree",
  trControl = trainControl("cv", number = 10)
  )
# Best tuning parameter mtry
model6$bestTune
# Make predictions on the test data
predictions6 <- model6 %>% predict(test.data6)
head(predictions6)
# Compute the average prediction error RMSE
RMSE(predictions6, test.data6$Q30)
varImp(model6)
```

```{r}
library(ggplot2)
scaled <- scale(preprepData.tot.na[,c(6,7,8,9,10,11,12,13,14)])
colnames(scaled) <- NULL

scaled <- as.data.frame(scaled)
colnames(scaled) <- colnames(preprepData.tot.na[,c(6,7,8,9,10,11,12,13,14)])
scaled$Sample <- preprepData.tot.na$SampleName


```

```{r}
library(reshape2)
library(ggplot2)

scaled$starting_value <- unlist(lapply(scaled$A260_280, function(x) {
  val <- x
  if (val > 1) {
    if (val > 10) {
      return("Very High")
    }
    return("High")
  }
  if (val < -1) {
    if (val < -10) {
      return("Very Low")
    }
    return("Low")
  }
  return("Mean")
}))

scaled.order.avail <- scaled[,c(1, 2, 6, 8, 3, 4, 5, 7, 9, 10, 11)]
scaled.order.retro <- scaled[,c(1, 9, 8, 2, 6, 3, 4, 5, 7, 10, 11)]
df_melted = melt(scaled.order.avail, id.vars = c('Sample', 'starting_value'))
ggplot(df_melted, aes(x = variable, y = value)) + geom_line(aes(color = starting_value, group = Sample)) + scale_color_manual(values = c("#f22116", "#16f2b7", "#49f216", "#165ff2")) + theme(axis.text.x = element_text(angle = 90))+ ggtitle("Metrics compared over the available time (Start: A260/280)")

df_melted = melt(scaled.order.retro, id.vars = c('Sample', 'starting_value'))
ggplot(df_melted, aes(x = variable, y = value)) + geom_line(aes(color = starting_value, group = Sample)) + scale_color_manual(values = c("#f22116", "#16f2b7", "#49f216", "#165ff2")) + theme(axis.text.x = element_text(angle = 90)) + ggtitle("Metrics compared over the origin time (Start: A260/280)")
```


