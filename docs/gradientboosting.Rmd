---
title: "GradientClassificationBoosting"
author: "Jouke Profijt"
date: "29-4-2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = '/Users/jouke/Projects/Analysis metrics/' )
```

```{r echo=FALSE}
library(DBI)
library(knitr)
library(ggplot2)
library(stringr)

prepData <- read.csv("data/GokuVsVegeta/QXTData.csv", sep = "\t", header = F)
colnames(prepData) <- c("SampleName", "Concentration", "A260_280", "A260_230", "ProcessStepId", "ExitDate", "ContainerPosition", "RequestId", "BatchId", "FinishedBy", "isFirstPriority", "FieldName", "DataType", "Value")
## establish connection to sqlite db
connection = dbConnect(RSQLite::SQLite(), "data/SQLITE/databaseFull.db")
samples <- dbReadTable(connection, "Samples")
dbDisconnect(connection)
samples$DNA_numbers <- as.factor(apply(samples, 1, function(x) {
  ids <- unlist(strsplit(x[1], "_"))
  ids[3]
  }))

samples$DesignNumber <- as.factor(apply(samples, 1, function(x) {
  ids <- unlist(strsplit(x[1], "_"))
  DN <- ids[6]
  if (is.null(DN) | is.na(DN)) {
    return(x["capturingKit"])
  } else {
    return(DN)
  }
  }))

samples <- subset(samples, ((grepl("DNA\\d+", DNA_numbers) )))
head(samples)
levels(samples$UniqueKits)

check_flowcell <- function(row) {
  x <- row["flowcell"]
  if (str_detect(x, regex("C[A-Z,0-9]{4}ANXX$"))) { return("HiSeq 1500")}
  if (str_detect(x, regex("C[A-Z,0-9]{4}ACXX$"))) { return("HiSeq 1000")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}ADXX$"))) { return("HiSeq 1500")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BCXX$"))) { return("HiSeq 1500")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BCXY$"))) { return("HiSeq 1500")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BBXX$"))) { return("HiSeq 4000")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BBXY$"))) { return("HiSeq 4000")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}CCXX$"))) { return("HiSeq X")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}CCXY$"))) { return("HiSeq X")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}ALXX$"))) { return("HiSeq X")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BGXX$"))) { return("NextSeq")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BGXY$"))) { return("NextSeq")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BGX2$"))) { return("NextSeq")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}AFXX$"))) { return("NextSeq")}
  if (str_detect(x, regex("A[A-Z,0-9]{4}$"))) { return("MiSeq")}
  if (str_detect(x, regex("B[A-Z,0-9]{4}$"))) { return("MiSeq")}
  if (str_detect(x, regex("D[A-Z,0-9]{4}$"))) { return("MiSeq")}
  if (str_detect(x, regex("G[A-Z,0-9]{4}$"))) { return("MiSeq")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}DMXX$"))) { return("NovaSeq")}
  return(row["Sequencer"]) # if no instrument type can be found, return the sequencer id to keep it destinguiasable

}
instruments <- function(row) {
  x <- row["Sequencer"]
  flowcell <- row["Flowcell"]
  if (str_detect(x, regex("HWI-M[0-9]{4}$"))) {
   return("MiSeq")
 }
  if (str_detect(x, regex("HWUSI"))) {
   return("Genome Analyzer IIx")
  }
  if (str_detect(x, regex("M[0-9]{5}$"))) {
   return("MiSeq")
  }
  if (str_detect(x, regex("HWI-C[0-9]{5}$"))) {
   return("HiSeq 1500")
  }
  if (str_detect(x, regex("C[0-9]{5}$"))) {
   return("HiSeq 1500")
  }
  if (str_detect(x, regex("HWI-D[0-9]{5}$"))) {
   return("HiSeq 2500")
  }
  if (str_detect(x, regex("D[0-9]{5}$"))) {
   return("HiSeq 2500")
  }
  if (str_detect(x, regex("J[0-9]{5}$"))) {
   return("HiSeq 3000")
  }
  if (str_detect(x, regex("K[0-9]{5}$"))) {
    return(check_flowcell(row))
  }
  if (str_detect(x, regex("E[0-9]{5}$"))) {
   return("HiSeq X")
  }
  if (str_detect(x, regex("NB[0-9]{6}$"))) {
   return("NextSeq")
  }
  if (str_detect(x, regex("NS[0-9]{6}$"))) {
   return("NextSeq")
  }
  if (str_detect(x, regex("MN[0-9]{5}$"))) {
   return("MiniSeq")
  }
  return(check_flowcell(row))
}

samples$Instrument <- apply(samples, 1, instruments)
samples$startDate <- as.Date(samples$startDate)
samples <- samples[order(samples$startDate),]
rm(connection)
head(samples)
```

```{r}
l <- list()
v <- c()
i <- 1
for (DNA_number in samples$DNA_numbers) {
  unique_combo <- paste0(DNA_number, samples$DesignNumber[i])
  if (is.null(l[unique_combo][[1]])) {
    l[unique_combo] <- i
    v <- append(v, "Not Reinserted")
  } else {
    v[l[unique_combo][[1]]] <- "Reinserted"
    v <- append(v, "Not Reinserted")
    l[unique_combo] <- i
  }
  i <- i + 1
}
samples$Used <- as.factor(v)
rm(v, l)
```
```{r}
connection = dbConnect(RSQLite::SQLite(), "data/SQLITE/databaseFull.db")
dbListTables(connection)
dbDisconnect(connection)
```

```{r}
library(dplyr)
connection = dbConnect(RSQLite::SQLite(), "data/SQLITE/databaseFull.db")

ASM <- dbReadTable(connection, "AlignmentSummaryMetrics")
ASM <- ASM[ASM$Category == "PAIR",]
hs <- dbReadTable(connection, "hsMetrics")
InsertSizes <- dbReadTable(connection, "InsertSizes")
RUNS <- dbReadTable(connection, "RUNS")
RunSummary <- dbReadTable(connection, "RunSummary")
FL <- dbReadTable(connection, "FlagstatMetrics")
dbDisconnect(connection)
RunSummary <- aggregate(RunSummary[, c(2:4, 6:7)], list(RunSummary$UniqueID), sum)


RunMetrics <- left_join(RUNS, RunSummary, by = c("UniqueID" = "Group.1"))
RunMetrics$Date <- as.Date(RunMetrics$Date)
data <- left_join(RunMetrics, samples, by = c("Sequencer"= "Sequencer", "Number" = "run", "Date" = "startDate"))
data <- left_join(data, ASM, by = c("ID" = "SampleID"))
data <- left_join(data, hs, by = c("ID" = "SampleID", "RunID.y" = "RunID"))
data <- left_join(data, InsertSizes, by = c("ID" = "SampleID", "RunID.y" = "RunID"))
data <- left_join(data, FL, by = c("ID" = "SampleID", "RunID.y" = "RunID"))
data$Used <- as.factor(data$Used)
str(data)
```

```{r}
data$Instrument <- as.factor(data$Instrument)
data2 <- na.omit(data)
Numeric_data <- subset(data2, select = -c(UniqueID,RunID.x, Number, Flowcell, Sequencer, Date, flowcell, project, capturingKit, DNA_numbers, DesignNumber, RunID.y, Category, PairOrientation, ID, BaitSet, Used))
Numeric_data <- as.data.frame(apply(Numeric_data, 2, as.numeric))
variance.data <- apply(Numeric_data, 2, var)
variance.data[variance.data == 0]
```

```{r}
Numeric_data <- subset(Numeric_data, select = -c(PFnoise, PFHQaligned, PFHQalignedQ20Bases, BadCycles, GenomeSize, BaitDesignEfficientcy,  PFBasesAligned, PFUQBasesAligned, OnBaitBases, NearBaitBases, OffBaitBases, OnTargetBases, ExcOverlapPct, AtDropout, GCDropout, TotalFail, SecondaryFail, SupplementaryPass, SupplementaryFail, DuplicateFail, MappedFail, PairedSeqFail, Read1Fail, Read2Fail, ProperPairFail, SelfAndMateFail, SingletonsFail, MateOnDiffChromosomeLowFail, MateOnDiffChromosomeHighFail)) # Remove values with 0 variance, aka not informative
```

```{r}
library(ggplot2)
Not.reinserted <- sum(data2$Used == "Not Reinserted")
Reinserted <- sum(data2$Used == "Reinserted")

df <- as.data.frame(c("Not Reinserted", "Reinserted"))
colnames(df) <- c("action")
df$num <- c(Not.reinserted, Reinserted)

ggplot(data = data2, aes(x=Used)) + geom_bar()
```

```{r}
library(ggplot2)
library(reshape2)
library(dplyr)

s <- subset(Numeric_data, select = c(AdapterPercentage,MedianAbsoluteDeviation, MinSize, StandardDeviation, W10, W20, W30, W40, W50, W60, W70, W80, W90, W99))
corMat <- round(cor(y=Numeric_data, x=s, method = "spearman", use = "complete.obs"), 2)



cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ theme(legend.position = "none") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + ggtitle("Correlations between variables")
cor.heatmap
```
```{r}

library(ggplot2)
library(reshape2)
library(dplyr)

s <- subset(Numeric_data, select = c(MeanReadLenght, ReadsAllignedInPairs, MaxSize, ReadPairs, TotalReads.x, PFreads.x, PFaligned, PFuniqueReads, PFHQalignedBases, PFalignedBases, PFmismatchRate, 
      PercentageUsableBasesOnBait, PercentageUsableBasesOnTarget, TotalPass, SecondaryPass, DuplicatePass, MappedPass, 
      PairedSeqPass, Read1Pass, Read2Pass, PoperPairPass, SelfAndMatePass, SingletonsPass, SingletonsPercentage, MateOnDiffChromosomeLowPass, MateOnDiffChromosomeHighPass))
corMat <- round(cor(y=Numeric_data, x=s, method = "spearman", use = "complete.obs"), 2)



cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ theme(legend.position = "none") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + ggtitle("Correlations between variables")
cor.heatmap
```

These metrics are related to the total number of reads.

```{r}

library(ggplot2)
library(reshape2)
library(dplyr)

s <- subset(Numeric_data, select = c(PFmismatchRate, PFHQErrorRate))
corMat <- round(cor(y=Numeric_data, x=s, method = "spearman", use = "complete.obs"), 2)



cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ theme(legend.position = "none") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + ggtitle("Correlations between variables")
cor.heatmap
```

```{r}

library(ggplot2)
library(reshape2)
library(dplyr)

s <- subset(Numeric_data, select = c(StrandBalance, MedianSize, MeanSize))
corMat <- round(cor(y=Numeric_data, x=s, method = "spearman", use = "complete.obs"), 2)



cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ theme(legend.position = "none") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + ggtitle("Correlations between variables")
cor.heatmap
```
```{r}

library(ggplot2)
library(reshape2)
library(dplyr)

s <- subset(Numeric_data, select = c(PFHQmedianMismatches, PFindelRate, ChimerasPercentage, MeanBaitCoverage, MeanTargetCoverage, MedianTargetCoverage, FoldEnrichment, TargetBasesPct20X))
corMat <- round(cor(y=Numeric_data, x=s, method = "spearman", use = "complete.obs"), 2)



cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ theme(legend.position = "none") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + ggtitle("Correlations between variables")
cor.heatmap
```

```{r}
Numeric_data$Used <- data2$Used
Numeric_data$kit <- data2$DesignNumber
Numeric_data <- as.data.frame(Numeric_data)
Numeric_data <- subset(Numeric_data, select = -c(AdapterPercentage,MedianAbsoluteDeviation, MinSize, W10, W20, W30, W40, W50, W60, W70, W80, W90, W99))
Numeric_data <- subset(Numeric_data, select = -c(MeanReadLenght, ReadsAllignedInPairs, MaxSize, ReadPairs, PFreads.x, PFaligned, PFuniqueReads, PFHQalignedBases, PFalignedBases, PFmismatchRate, 
      PercentageUsableBasesOnBait, PercentageUsableBasesOnTarget, TotalPass, SecondaryPass, DuplicatePass, MappedPass, 
      PairedSeqPass, Read1Pass, Read2Pass, PoperPairPass, SelfAndMatePass, SingletonsPass, SingletonsPercentage, MateOnDiffChromosomeLowPass, MateOnDiffChromosomeHighPass, PFHQErrorRate))

Numeric_data <- subset(Numeric_data, select = -c(MeanSize, MeanTargetCoverage, FoldEnrichment))
Unlabeled <- subset(Numeric_data, select = -c(Used, kit))

head(Numeric_data)
```

```{r}
library(tidyverse)
library(caret)
library(xgboost)
Numeric_data$Instrument <- data2$Instrument
Numeric_data_u <-Numeric_data


training.data <- Numeric_data_u$Used %>% 
  createDataPartition(p = 0.8, list = FALSE)
set.seed(123)
train.data  <- Numeric_data_u[training.data, ]
test.data <- Numeric_data_u[-training.data, ]
```

```{r}
# Fit the model on the training set
set.seed(123)
model <- train(
  Used ~., data = train.data, method = "xgbTree",
  trControl = trainControl("cv", number = 10)
  )
# Best tuning parameter
model$bestTune
```

```{r}
predicted.classes <- model %>% predict(test.data)
```
```{r}
mean(predicted.classes == test.data$Used)
test.data$predicted <- predicted.classes

table(test.data$Used, test.data$predicted)
```

```{r}
varImp(model)
```
Standard Deviation: SD of insert sizes over the core of the distribution

Intensity: The average of the A channel, measured at Cycle one of sequencing, averaged over the clusters

PFUQaligned: The number of reads that were aligned to the reference sequence with a mapping quality of Q20 or higher

ChimerasPercentage: Sequences formed from two or more biological sequences joined together, contamination of samples? Fraction of reads that map outside of the maximum insertsize, or have two ends mapping to different chromosomes.

Q30: The percentage of reads that have a quality score of 30 or higher

TotalREads: total number of reads in the run\

StrandBalance: The number of PF reads aligned to the positive strand of the genome divided by the number of PF reads aligned to the genome.

TargetBasespct10X: The fraction of all target bases achieving 10X or greater coverage.

HsLibrarySize: The estimated number of unique molecules in the selected part of the library.

SelectedBasesPercentage: The fraction of Aligend Bases located on or near a baited regio

```{r}
library(ROCR)
a<- as.numeric(test.data$predicted)

b<- as.numeric(test.data$Used)

pred <- prediction(a, b)
auc.tmp <- performance(pred,"auc")
auc <- as.numeric(auc.tmp@y.values)
auc
```

```{r}
filtered <- prepData[grepl("DNA-\\d+", prepData$SampleName),]
filtered$SampleName[1] <- "DNA-000557"
header <- levels(as.factor(filtered$FieldName))
DNA.Numbers <- unique(filtered[1:4])

DNA.Numbers[duplicated(DNA.Numbers$SampleName),]
UniqueDNA <- DNA.Numbers[!(duplicated(DNA.Numbers$SampleName) | duplicated(DNA.Numbers$SampleName, fromLast = TRUE)), ]

UniqueDNA$SampleName <- apply(UniqueDNA, 1, function(x) {
  return(gsub('-', '', x["SampleName"]))
})
```
```{r}
library(ggplot2)
data2$DNA_numbers <- as.vector(data2$DNA_numbers)
preprepData <- inner_join(UniqueDNA, data2, by=c("SampleName" = "DNA_numbers"))
preprepData$A260_230 <- as.numeric(preprepData$A260_230)
preprepData$A260_280 <- as.numeric(preprepData$A260_280)
preprepData$Concentration <- as.numeric(preprepData$Concentration)
ggplot(preprepData, aes(x=Concentration, y=ChimerasPercentage)) + geom_point()
ggplot(preprepData, aes(x=A260_280, y=ChimerasPercentage)) + geom_point()
ggplot(preprepData, aes(x=A260_230, y=ChimerasPercentage)) + geom_point()

ggplot(preprepData, aes(x=Date, y=A260_280)) + geom_point()
```
```{r}
ggplot(preprepData, aes(x=Concentration, y=Q30)) + geom_point()
ggplot(preprepData, aes(x=A260_280, y=Q30)) + geom_point()
ggplot(preprepData, aes(x=A260_230, y=Q30)) + geom_point()
```
```{r}
ggplot(preprepData, aes(x=Concentration, y=TargetBasesPct10X)) + geom_point()
ggplot(preprepData, aes(x=A260_280, y=TargetBasesPct10X)) + geom_point()
ggplot(preprepData, aes(x=A260_230, y=TargetBasesPct10X)) + geom_point()
```

```{r}
library(factoextra)
library(ggfortify)

res.pca <- prcomp(Unlabeled, scale = TRUE)
fviz_eig(res.pca)
```

```{r}
autoplot(res.pca, data = Numeric_data, colour = "Used")
```

```{r}
library(caret)
 
preproc1 <- preProcess(subset(Numeric_data, select = -c(Used, kit)), method=c("center", "scale"))
 
norm1 <- predict(preproc1, subset(Numeric_data, select = -c(Used, kit)))
```


```{r}
library(tidyverse)
library(caret)
library(xgboost)
normU <- norm1
normU$Used <- Numeric_data$Used


training.data2 <- normU$Used %>% 
  createDataPartition(p = 0.8, list = FALSE)
set.seed(123)
train.data2  <- normU[training.data2, ]
test.data2 <- normU[-training.data2, ]
```

```{r}
# Fit the model on the training set
set.seed(123)
model2 <- train(
  Used ~., data = train.data2, method = "xgbTree",
  trControl = trainControl("cv", number = 10)
  )
# Best tuning parameter
model2$bestTune
```

```{r}
predicted.classes <- model2 %>% predict(test.data2)
mean(predicted.classes == test.data2$Used)
```

```{r}
varImp(model2)
```

Chimeras Percentage, Interesting. Chimeras can be seen as contamination of samples/reads. As this metric seems to contri

```{r}
library(ROCR)
a<- as.numeric(predicted.classes)

b<- as.numeric(test.data2$Used)

pred <- prediction(a, b)
auc.tmp <- performance(pred,"auc")
auc <- as.numeric(auc.tmp@y.values)
auc
```
```{r}
summary(Numeric_data$ChimerasPercentage)
```

```{r}
library(tidyverse)
library(caret)
library(xgboost)
normKits <- norm1
normKits$Kit <- droplevels(Numeric_data_0$kit)
levels(Numeric_data_0$kit)

training.data3 <- normKits$Kit %>% 
  createDataPartition(p = 0.8, list = FALSE)
set.seed(123)
train.data3  <- normKits[training.data3, ]
test.data3 <- normKits[-training.data3, ]
```


```{r}
library(tidyverse)
library(caret)
library(xgboost)
# Split the data into training and test set
coverage_prediction_data <- subset(Numeric_data, select = -c(TargetBasesPct10X, TargetBasesPct30X, TargetBasesPct40X, TargetBasesPct50X, TargetBasesPct100X, TargetBasesPct1X, TargetBasesPct2X, MeanTargetCoverage, MedianTargetCoverage))
set.seed(123)
training.samples4 <- Numeric_data$TargetBasesPct20X %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data4  <- Numeric_data[training.samples4, ]
test.data4 <- Numeric_data[-training.samples4, ]
```

```{r}
# Fit the model on the training set
set.seed(123)
model4 <- train(
  TargetBasesPct20X ~., data = train.data4, method = "xgbTree",
  trControl = trainControl("cv", number = 10)
  )
# Best tuning parameter mtry
model4$bestTune
# Make predictions on the test data
predictions4 <- model4 %>% predict(test.data4)
head(predictions4)
# Compute the average prediction error RMSE
RMSE(predictions4, test.data4$TargetBasesPct20X)
```

```{r}
varImp(model4)
```

```{r}
training.samples5 <- coverage_prediction_data$TargetBasesPct20X %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data5  <- coverage_prediction_data[training.samples5, ]
test.data5 <- coverage_prediction_data[-training.samples5, ]
```

```{r}
# Fit the model on the training set
set.seed(123)
model5 <- train(
  TargetBasesPct20X ~., data = train.data5, method = "xgbTree",
  trControl = trainControl("cv", number = 10)
  )
# Best tuning parameter mtry
model5$bestTune
# Make predictions on the test data
predictions5 <- model5 %>% predict(test.data5)
head(predictions5)
# Compute the average prediction error RMSE
RMSE(predictions5, test.data5$TargetBasesPct20X)
varImp(model5)
max()
```

```{r}
q30_data <- subset(Numeric_data, select = -c(W99, W90, W80, W70, W60, W50, W40, W30, W20, W10))
training.samples6 <- q30_data$Q30 %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data6  <- q30_data[training.samples6, ]
test.data6 <- q30_data[-training.samples6, ]
```

```{r}
# Fit the model on the training set
set.seed(123)
model6 <- train(
  Q30 ~., data = train.data6, method = "xgbTree",
  trControl = trainControl("cv", number = 10)
  )
# Best tuning parameter mtry
model6$bestTune
# Make predictions on the test data
predictions6 <- model6 %>% predict(test.data6)
head(predictions6)
# Compute the average prediction error RMSE
RMSE(predictions6, test.data6$Q30)
varImp(model6)
```
