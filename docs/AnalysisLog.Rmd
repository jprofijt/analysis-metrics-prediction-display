---
title: "AnalysisLog"
author: "Jouke Profijt"
date: "6/2/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = 'C:/Users/Jouke/Documents/analysis-metrics-prediction-display/' )
```

# 1. Data preparation
```{r echo=FALSE}
library(stringr)
library(dplyr)


# Retrieve DNA isolation and sample preparation data from supplied csv:
prepData <- read.csv2("data/GokuVsVegeta/QXTData.csv", sep = "\t", header = F, dec = ",")
colnames(prepData) <- c("SampleName", "Concentration", "A260_280", "A260_230", "ProcessStepId", "ExitDate", "ContainerPosition", "RequestId", "BatchId", "FinishedBy", "isFirstPriority", "FieldName", "DataType", "Value")

prepData.pur <- prepData %>% select(SampleName, A260_230, A260_280)

prepData.pur <- distinct(prepData.pur)

# format DNA number
prepData.pur$SampleName <- apply(prepData.pur, 1, function(x) {
  str_remove(x[1], "-")
})

prepData.pur$A260_230 <- apply(prepData.pur, 1, function(x) {
  as.numeric(sub(",", ".", x[2], fixed = TRUE))
})

prepData.pur$A260_280 <- apply(prepData.pur, 1, function(x) {
  as.numeric(sub(",", ".", x[3], fixed = TRUE))
})
head(prepData.pur)
```

```{r}
library(DBI)
library(stringr)
# Retrieve parsed sample sheets from database file
connection = dbConnect(RSQLite::SQLite(), "data/SQLITE/databaseFull.db")
samples <- dbReadTable(connection, "Samples")
dbDisconnect(connection)
samples$DNA_numbers <- as.factor(apply(samples, 1, function(x) {
  ids <- unlist(strsplit(x[1], "_"))
  ids[3]
}))

# Parse Sample capturing kit design number from sample ID
samples$DesignNumber <- as.factor(apply(samples, 1, function(x) {
  ids <- unlist(strsplit(x[1], "_"))
  DN <- ids[6]
  if (is.null(DN) | is.na(DN)) {
    return(x["capturingKit"])
  } else {
    return(DN)
  }
  }))

# only retrieve samples with a correct DNA identifier
samples <- subset(samples, ((grepl("DNA\\d+", DNA_numbers) )))


instruments <- function(row) {
  # function to parse sequencer machine used for the sample using the sequencer id
  x <- row["Sequencer"]
  flowcell <- row["Flowcell"]
  if (str_detect(x, regex("HWI-M[0-9]{4}$"))) {
   return("MiSeq")
 }
  if (str_detect(x, regex("HWUSI"))) {
   return("Genome Analyzer IIx")
  }
  if (str_detect(x, regex("M[0-9]{5}$"))) {
   return("MiSeq")
  }
  if (str_detect(x, regex("HWI-C[0-9]{5}$"))) {
   return("HiSeq 1500")
  }
  if (str_detect(x, regex("C[0-9]{5}$"))) {
   return("HiSeq 1500")
  }
  if (str_detect(x, regex("HWI-D[0-9]{5}$"))) {
   return("HiSeq 2500")
  }
  if (str_detect(x, regex("D[0-9]{5}$"))) {
   return("HiSeq 2500")
  }
  if (str_detect(x, regex("J[0-9]{5}$"))) {
   return("HiSeq 3000")
  }
  if (str_detect(x, regex("K[0-9]{5}$"))) {
    return(check_flowcell(row))
  }
  if (str_detect(x, regex("E[0-9]{5}$"))) {
   return("HiSeq X")
  }
  if (str_detect(x, regex("NB[0-9]{6}$"))) {
   return("NextSeq")
  }
  if (str_detect(x, regex("NS[0-9]{6}$"))) {
   return("NextSeq")
  }
  if (str_detect(x, regex("MN[0-9]{5}$"))) {
   return("MiniSeq")
  }
  return(check_flowcell(row))
}

check_flowcell <- function(row) {
  # secondary function to parse sequencer machine used for the sample using the flowcell id
  x <- row["flowcell"]
  if (str_detect(x, regex("C[A-Z,0-9]{4}ANXX$"))) { return("HiSeq 1500")}
  if (str_detect(x, regex("C[A-Z,0-9]{4}ACXX$"))) { return("HiSeq 1000")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}ADXX$"))) { return("HiSeq 1500")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BCXX$"))) { return("HiSeq 1500")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BCXY$"))) { return("HiSeq 1500")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BBXX$"))) { return("HiSeq 4000")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BBXY$"))) { return("HiSeq 4000")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}CCXX$"))) { return("HiSeq X")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}CCXY$"))) { return("HiSeq X")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}ALXX$"))) { return("HiSeq X")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BGXX$"))) { return("NextSeq")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BGXY$"))) { return("NextSeq")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BGX2$"))) { return("NextSeq")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}AFXX$"))) { return("NextSeq")}
  if (str_detect(x, regex("A[A-Z,0-9]{4}$"))) { return("MiSeq")}
  if (str_detect(x, regex("B[A-Z,0-9]{4}$"))) { return("MiSeq")}
  if (str_detect(x, regex("D[A-Z,0-9]{4}$"))) { return("MiSeq")}
  if (str_detect(x, regex("G[A-Z,0-9]{4}$"))) { return("MiSeq")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}DMXX$"))) { return("NovaSeq")}
  return(row["Sequencer"]) # if no instrument type can be found, return the sequencer id to keep it destinguiasable

}

# format sample sheet information
samples$Instrument <- apply(samples, 1, instruments)
samples$startDate <- as.Date(samples$startDate)
samples <- samples[order(samples$startDate),]


# group sample into Not reinserted or Reinserted when they have been reused as identiefied by the DNA_number
l <- list()
v <- c()
i <- 1
for (DNA_number in samples$DNA_numbers) {
  unique_combo <- paste0(DNA_number, samples$DesignNumber[i])
  if (is.null(l[unique_combo][[1]])) {
    l[unique_combo] <- i
    v <- append(v, "Not Reinserted")
  } else {
    v[l[unique_combo][[1]]] <- "Reinserted"
    v <- append(v, "Not Reinserted")
    l[unique_combo] <- i
  }
  i <- i + 1
}
samples$Used <- as.factor(v)
rm(v, l)
head(samples)
```

```{r}
library(dplyr)
# Retrieve Post-bam and Sequencing information from database
## Sequencing: Runs, RunSummary & CD
## Post-Bam: ASM, hs, InsertSizes, FL
connection = dbConnect(RSQLite::SQLite(), "data/SQLITE/databaseFull.db")
ASM <- dbReadTable(connection, "AlignmentSummaryMetrics")
ASM <- ASM[ASM$Category == "PAIR",]
hs <- dbReadTable(connection, "hsMetrics")
InsertSizes <- dbReadTable(connection, "InsertSizes")
RUNS <- dbReadTable(connection, "RUNS")
RunSummary <- dbReadTable(connection, "RunSummary")
res <- dbSendQuery(connection, "
                  SELECT
                  Samples.ID as SampleID,
                  avg(Lanes.DensityMAX) as ClusterDensity,
                  avg(Lanes.Q30) as Average_Q30,
                  avg(Lanes.LegacyPhasing) as Phasing,
                  avg(Lanes.LegacyPrePhasing) as PrePhasing,
                  avg(Lanes.ClusterMAX) as ClusterPF
                  FROM Samples 
                  INNER JOIN RUNS ON Samples.Sequencer==RUNS.Sequencer AND Samples.Run==RUNS.Number AND Samples.startDate==RUNS.Date 
                  INNER JOIN RunSummary ON RUNS.UniqueID==RunSummary.UniqueID
                  INNER JOIN Lanes ON RUNS.UniqueID==Lanes.UniqueID
                  GROUP BY Samples.ID
                  ORDER BY RUNS.Date")
CD <- dbFetch(res)
FL <- dbReadTable(connection, "FlagstatMetrics")
dbDisconnect(connection)
RunSummary <- aggregate(RunSummary[, c(2:4, 6:7)], list(RunSummary$UniqueID), sum)

# combine data into one
RunMetrics <- left_join(RUNS, RunSummary, by = c("UniqueID" = "Group.1"))
RunMetrics$Date <- as.Date(RunMetrics$Date)
data <- left_join(RunMetrics, samples, by = c("Sequencer"= "Sequencer", "Number" = "run", "Date" = "startDate"))

data <- left_join(prepData.pur, data, by = c("SampleName" = "DNA_numbers") )
data <- left_join(data, CD, by = c("ID" = "SampleID"))
data <- left_join(data, ASM, by = c("ID" = "SampleID"))
data <- left_join(data, hs, by = c("ID" = "SampleID", "RunID.y" = "RunID"))
data <- left_join(data, InsertSizes, by = c("ID" = "SampleID", "RunID.y" = "RunID"))
data <- left_join(data, FL, by = c("ID" = "SampleID", "RunID.y" = "RunID"))

data$Used <- as.factor(data$Used)
data$Instrument <- as.factor(data$Instrument)
dbDisconnect(connection)
rm(ASM,hs,InsertSizes,FL,CD,RunMetrics, RUNS, RunSummary, res, connection, DNA_number, i, unique_combo, v, check_flowcell, instruments)

# omit na values
data2 <- na.omit(data)

complete.data <- data.frame(data2[c(1,4:9,15:21, 27,28,47,103)], apply(data2[c(2,3,10:14,22:26, 29:46, 48:102, 104:142)], 2, as.numeric))

variance.data <- apply(complete.data[19:142], 2, var)

# Remove nummeric columns with 0 varance, as they do not provide any usable information
complete.data.var <- complete.data %>% select(c(names(complete.data[1:18]), names(variance.data[variance.data != 0])))
head(complete.data.var)
```


```{r echo=FALSE}
length(complete.data.var$Yield) == sum(complete.data.var$Yield == complete.data.var$ProjectedYield)
```
Yield and Projected yield are the same in our instance so Projected yield will be removed from the data

```{r}
length(complete.data.var$TotalReads.x) == sum(complete.data.var$TotalReads.x == complete.data.var$TotalReads.y)
```
Total reads is duplicated so we remove 1 of the two columns.

```{r}
length(complete.data.var$TotalReads.x) == sum(complete.data.var$TotalReads.x == complete.data.var$PFreads.x)
```
```{r}
length(complete.data.var$TotalReads.x) == sum(complete.data.var$TotalReads.y == complete.data.var$PFreads.y)
```
The number of reads passing filter is always equal to The total reads, and is also duplicated

```{r}
length(complete.data.var$TotalReads.x) == sum(complete.data.var$Read1Pass == complete.data.var$Read2Pass)
```
Duplicated Read 1 & read 2 always have the same pass count for the flagstat metrics

```{r}
length(complete.data.var$MeanBaitCoverage) == sum(complete.data.var$MeanBaitCoverage == complete.data.var$MeanTargetCoverage)
```
```{r}
length(complete.data.var$BaitTerritory) == sum(complete.data.var$BaitTerritory == complete.data.var$TargetTerritory)
```

lastly Q30 is a percentage and should not exceed 100%, we can use average Q30 per lane instead.

```{r}
complete.data.edit <- complete.data.var %>% select(!c(ProjectedYield, Q30, Read2Pass, TotalReads.y, PFreads.x, PFreads.y, BaitSet, TargetTerritory, Category, PairOrientation)) # bait set has 1 level, as do Category and PairOrientation
```


```{r}
str(complete.data.edit)
```

This leaves us with a dataset of 6960 samples, with 106 variables.


# 2. Correlation analysis

```{r}
library(Hmisc)

# Size of Correlation	Interpretation
# .90 to 1.00 (−.90 to −1.00)	Very high positive (negative) correlation
# .70 to .90 (−.70 to −.90)	High positive (negative) correlation
# .50 to .70 (−.50 to −.70)	Moderate positive (negative) correlation
# .30 to .50 (−.30 to −.50)	Low positive (negative) correlation
# .00 to .30 (.00 to −.30)	negligible correlation
# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3576830/

get.correlation <- function(x) {
  if (x < -0.3) {
    if ( x < -0.5) {
      if (x < -0.7) {
        if (x < -0.9) {
          return("Very high negatie correlation")
        }
      return("High negative correlation")
    }
    return("Moderate negative correlation")
    }
    return("Low negative correlation")
  }
  if (x > 0.3) {
    if ( x > 0.5) {
      if (x > 0.7){
        if (x > 0.9) {
          return("Very high positive correlation")
        }
        return("High positive correlation")
      }
      return("Moderate postive correlation")   
    }
    return("Low postive correlation")
  }
  return("negligible correlation")
}

perform_cor.tests <- function(x, y, method="spearman") {
  metrics <- data.frame(metric.x=character(), # x metric name
                   metric.y=character(),# y metric name
                   Significant=logical(), # significant p-value
                   significance.level=double(), # significance level
                   rho=double(), # correlation coefficent
                   verdict=character(), # correlation verdict
                   nonneg=double(), # rho is not neglegable
                   stringsAsFactors=FALSE)
  
  res2 <- rcorr(as.matrix(data.frame(y, x)), type = method)
  
  for (name in colnames(x)) {
    for (y.name in colnames(y)) {
      p <- as.numeric(res2$P[name, y.name])
      chr.p <- as.character(p)
      if (p < .05) {
        chr.p <- "P<.05"
      }
      if (p < .01) {
        chr.p <- "P<.01"
      }
      if (p < .001) {
        chr.p <- "P<.001"
      }
      if (p < .0001) {
        chr.p <- "P<.0001"
      }
      r <- as.numeric(res2$r[name, y.name])
      metrics[nrow(metrics) + 1,] <- c(name, y.name, p < 0.05, chr.p , signif(r, digits = 2), get.correlation(r), (r > 0.3 | (-0.3) > r))
    }
  }
  
  return(metrics)
}
```

## Preparation metrics vs Sequencing Metrics

```{r}
library(reshape2)
library(ggplot2)
interop <- complete.data.edit %>% select(Aligned, Intensity, ClusterDensity, Average_Q30, Phasing, PrePhasing, ClusterPF) # Yield excluded as it has some affect on all metrics, we look for more direct interactions
puritys <- complete.data.edit %>% select(A260_230, A260_280)

corMat <- round(cor(x=interop, y=puritys, method = "spearman", use = "complete.obs"), 2)



pur.cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + xlab("Interop Metrics") + ylab("DNA preparation metrics") + ggtitle("Interop vs DNA purities")

pur.cor.heatmap


res <- perform_cor.tests(interop, puritys)
res[res$Significant == T & res$nonneg == T, ]
rm(puritys, corMat, pur.cor.heatmap)
```
Observation:
* There does not seem to be direct correlations with dna puritys and Sequencing metrics.

# Sequencing metrics(interop) correlation heatmaps to Post-bam Metrics

## Alignment Summary Metrics
```{r}
library(reshape2)
library(Hmisc)

ASM <- complete.data.edit %>% select(TotalReads.x, PFaligned, PFalignedBases, PFHQmedianMismatches, PFmismatchRate, PFHQErrorRate, PFindelRate, MeanReadLenght, ReadsAllignedInPairs, StrandBalance, ChimerasPercentage, AdapterPercentage)


corMat <- round(cor(x=interop, y=ASM, method = "spearman", use = "complete.obs"), 2)


ASM.cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + xlab("Interop Metrics") + ylab("Alignment Summary Metrics") + ggtitle("Sequencing vs Alignment Summary Metrics")

ASM.cor.heatmap

res <- perform_cor.tests(interop, ASM)
sig <- res[res$Significant == T & res$nonneg == T,]

results <- sig[c(1,2,4,5,6)]

results

library(gridExtra)
png("ASM_heatmap.png", height =205*nrow(results), width = 800*ncol(results), res = 400)
t <- tableGrob(results, rows = NULL, cols = c("Sequencing Metric", "Post-Bam metric", "Significance Level", "Correlation Coefficent", "Relation"), theme = ttheme_minimal())

grid.arrange(ASM.cor.heatmap, t, nrow=2, heights=c(1.5, 2))
dev.off()
```
Observations:
* Aligned (The percentage of reads that align to the PhiX genome)
  * positivly impacts the chimeras percentage
  * positivly impacts the Adapter sequencers percentage
  * negativly impacts the rate of insertions and deletions

* The sequencing intensity:
  * Negativly impacts the median number of mismathces
  * Negativly impacts the mismatch rate
  * Negativly impacts the error rate
  * When your sequencing intensity is higher, it suggests that there will be less mismatches/errors, which is also expected, if the intensity is more clear, there is a higher chance of a correct base call 

* Q30:
  * Negativly impacts the median number of mismathces
  * Negativly impacts the mismatch rate
  * Negativly impacts the error rate
  * These 3 are expected results as when you have a phred score of 10, there is a 90% probability that a base was called incorrectly. Meanwhile if there are more bases with a 99.99% probability(Q30) you expect less mismatches in alignment. 
  * Negativly impacts the strandbalance, when the base calls are more accurate, there are less reads that align to the positve strand of the genome versus the genome.
  * Negativly impacts the chimeras percentage, when base calls are more accurate, there are less reads that could be contaminated by reads originating from another source. 

* Phasing
  * Positvly impacts the mismatch and error rate, when there is more phasing while sequencing it could be that there are more mismatches/errors in the bases.

* PrePhasing
  * Positivly impacts the mismatch and error rate, when there is more prephasing while sequencing it could be that there are more mismatches/errors in the bases that were called. 
  * Positivly impacts the strandbalance, when there is more prephasing, it suggests that more reads will allign to the positive strand of the genome versus the genome. 

* Clusters passing filters
  * Negativly impacts mismatch/error rate & median mismatches, when more clusters pass the filters there will be less errors/mismatches in the sequenced reads.

Metrics that could have interactions: interop
  Aligned
  Intensity
  Q30
  Phasing
  PrePhasing
  ClustersPF
  
Metrics that could have interactions:Post-bam:
  Chimeras
  Adapter sequences
  indels
  mismatch rate
  error rate
  median mismatch rate
  

## HS Metrics

```{r}
library(DBI)
library(dplyr)
library(ggplot2)
library(reshape2)
connection = dbConnect(RSQLite::SQLite(), "data/SQLITE/databaseFull.db")
hsm <- dbListFields(connection, "hsMetrics")
hsm <- hsm[hsm %in% names(complete.data.edit)]
HS <- complete.data.edit %>% select(hsm)

HS1 <- HS[1:10]
corMat <- round(cor(x=HS1, y=interop, method = "spearman", use = "complete.obs"), 2)



hs.cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + xlab("Hs Metrics") + ylab("Interop") + ggtitle("Sequencing vs HS-metrics 1")

hs.cor.heatmap


library(Hmisc)


res <- perform_cor.tests(interop, HS1)
sig <- res[res$Significant == T & res$nonneg == T,]

results <- sig[c(1,2,4,5,6)]

results

library(gridExtra)
png("HS1t_heatmap.png", height =410*nrow(results), width = 800*ncol(results), res = 400)
t <- tableGrob(results, rows = NULL, cols = c("Sequencing Metric", "Post-Bam metric", "Significance Level", "Correlation Coefficent", "Relation"), theme = ttheme_minimal())

grid.arrange(hs.cor.heatmap, t, nrow=2)
dev.off()
```
Observations:
* Aligned
  Positivly impacts the fraction of bases on or near baits that are covered by baits. The more of the sample that alignes to the PhiX genome the more  bases will be near baits.

* Cluster Density
  * Negativly impacts the bait terretory, more dense clusters equals less bases per bait
  * Negativly impactes the mean Bait coverage, mean target coverage, and median target coverage, more dense clusters could mean that the target/bait regions are smaller

* Q30
  * Negativly impacts the meanBait/target coverage, higher probabilitys of base calls results in less coverage for baits and target regions.
  
* Clusters passing filters
  * Negativly impacts the meanBait/target coverage, more clusters that pass the quality filter equals less Bait/target coverage
  
Metrics that could have interactions: Interop
  Aligned
  ClusterDensity
  Average_Q30
  ClusterPF
  
Metrics that could have interactions Post-bam:
  OnBaitVSselected
  BaitTerritory
  MeanBaitCoverage
  MedianTargetCoverage
  MeanTargetCoverage
  


```{r}
HS2 <- HS[11:20]
corMat <- round(cor(x=HS2, y=interop, method = "spearman", use = "complete.obs"), 2)



hs.cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + xlab("Hs Metrics") + ylab("Interop") + ggtitle("Sequencing vs HS-metrics 2")

hs.cor.heatmap
ggsave(
  "Hs2_heatmap.png",
  plot = hs.cor.heatmap,
  dpi = 300,
  limitsize = TRUE,
)
library(Hmisc)


res <- perform_cor.tests(interop, HS2)
sig <- res[res$Significant == T & res$nonneg == T,]

results <- sig[c(1,2,4,5,6)]

results

library(gridExtra)
png("HS2t_heatmap.png", height =410*nrow(results), width = 800*ncol(results), res = 400)
t <- tableGrob(results, rows = NULL, cols = c("Sequencing Metric", "Post-Bam metric", "Significance Level", "Correlation Coefficent", "Relation"), theme = ttheme_minimal())

grid.arrange(hs.cor.heatmap, t, nrow=2)
dev.off()
```

Observations:
* Aligned
  * Positivly affects the ExcMapQPct, or the fraction of aligned bases that were filtered out because they were in reads with low mapping quality
  * Positivly affects the Fold 80 base penalty, or the fold of additional sequencing required to ensure that 80% of the target bases achieve the mean coverage. 
  
* Cluster Density
  * Positivly impacts the fold by which the baited region has been amplified above genomic background.
  * Negativly impacts the zeroCVGtargetsPercentage or the fraction of targets that did not reach coverage=1 over any base
  * Negativly impacts the EXCBaseQPct or the fraction of aligned bases that were filtered out becouse of low quality
  * Positivly impacts the fraciton of target bases that acieve some kind of coverage. 
  
* Q30
  * Negativly impacts the fold80 base penalty.
  
Clusters Passing Filters:
  * Negativly impacts the fold80 base penalty.
  
  
Metrics that could have interactions:
  ExtMapQPct
  Fold80 base penalty
  FoldEnrichment
  ZeroCVGtargetsPercentage
  TargetBasesPctXXX


  
```{r}
HS3 <- HS[21:30]
corMat <- round(cor(x=HS3, y=interop, method = "spearman", use = "complete.obs"), 2)



hs.cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + xlab("Hs Metrics") + ylab("Interop") + ggtitle("Sequencing vs HS-metrics 3")

hs.cor.heatmap


res <- perform_cor.tests(interop, HS3)
sig <- res[res$Significant == T & res$nonneg == T,]

results <- sig[c(1,2,4,5,6)]

results

library(gridExtra)
png("HS3t_heatmap.png", height =410*nrow(results), width = 800*ncol(results), res = 400)
t <- tableGrob(results, rows = NULL, cols = c("Sequencing Metric", "Post-Bam metric", "Significance Level", "Correlation Coefficent", "Relation"), theme = ttheme_minimal())

grid.arrange(hs.cor.heatmap, t, nrow=2)
dev.off()
```
Observations:
The cluster density impacts the amount of target bases achieving the desired coverage

the q30 & Clusters passing filters negativly impacts the penalty given to the target design to achieve a certain coverage for that target.

Metrics that could have interactions:
  HsPenalty
  



```{r}
HS4 <- HS[31:34]
corMat <- round(cor(x=HS4, y=interop, method = "spearman", use = "complete.obs"), 2)



hs.cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + xlab("Hs Metrics") + ylab("Interop") + ggtitle("Sequencing vs HS-metrics 4")

hs.cor.heatmap

res <- perform_cor.tests(interop, HS4)
sig <- res[res$Significant == T & res$nonneg == T,]

results <- sig[c(1,2,4,5,6)]

results

library(gridExtra)
png("HS4t_heatmap.png", height =410*nrow(results), width = 800*ncol(results), res = 400)
t <- tableGrob(results, rows = NULL, cols = c("Sequencing Metric", "Post-Bam metric", "Significance Level", "Correlation Coefficent", "Relation"), theme = ttheme_minimal())

grid.arrange(hs.cor.heatmap, t, nrow=2)
dev.off()
```

Observations:
The ClusterDensity seems to affect the sesnitifty to detect Hetrozygous SNPs and the Hetrozygous SNP sensitifity scaled to th e Qscore in a positive way.

as said earlier, the Q30 and Clusters passing filter affect the hybrid selection penalty given to targets.

Metrics that could have interactions:
  HetSNPsensitivity
  HetSNPQ
  


## Insert Size metrics

```{r}
connection = dbConnect(RSQLite::SQLite(), "data/SQLITE/databaseFull.db")
ISM <- dbListFields(connection, "InsertSizes")
ISM <- ISM[ISM %in% names(complete.data.edit)]
IS <- complete.data.edit %>% select(ISM)
corMat <- round(cor(x=interop, y=IS, method = "spearman", use = "complete.obs"), 2)



IS.cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + xlab("Interop Metrics") + ylab("Insert Size Metrics") + theme(legend.position = "none") + ggtitle("Interop vs InsertSize metrics")

IS.cor.heatmap


res <- perform_cor.tests(interop, IS)
sig <- res[res$Significant == T & res$nonneg == T,]

results <- sig[c(1,2,4,5,6)]

results

library(gridExtra)
png("ISt_heatmap.png", height =410*nrow(results) *2, width = 800*ncol(results), res = 400)
t <- tableGrob(results, rows = NULL, cols = c("Sequencing Metric", "Post-Bam metric", "Significance Level", "Correlation Coefficent", "Relation"), theme = ttheme_minimal())

grid.arrange(IS.cor.heatmap, t, nrow=2, heights=c(2, 1))
dev.off()
```
Observations:
* reads aligned to the PhiX genome:
  * negativly affects the median and mean insert size

* Q30
  Positivly affects the the width of bins that encompaass all read pairs.
  
Metrics that could have interactions:
  Mean Size
  Median Size
  
## FLagstat Metrics

```{r}
connection = dbConnect(RSQLite::SQLite(), "data/SQLITE/databaseFull.db")
FLM <- dbListFields(connection, "FlagstatMetrics")
FLM <- FLM[FLM %in% names(complete.data.edit)]
FL <- complete.data.edit %>% select(FLM)

corMat <- round(cor(x=FL, y=interop, method = "spearman", use = "complete.obs"), 2)



fl.cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + xlab("FlagStat metrics") + ylab("Interop") + ggtitle("Correlations between Interop vs hs metrics")

fl.cor.heatmap
ggsave(
  "Flagstat_heatmap.png",
  plot = fl.cor.heatmap,
  dpi = 300,
  limitsize = TRUE,
)

res <- perform_cor.tests(interop, FL)
sig <- res[res$Significant == T & res$nonneg == T,]

results <- sig[c(1,2,4,5,6)]

results

library(gridExtra)
png("FLt_heatmap.png", height =310*nrow(results), width = 810*ncol(results), res = 400)
t <- tableGrob(results, rows = NULL, cols = c("Sequencing Metric", "Post-Bam metric", "Significance Level", "Correlation Coefficent", "Relation"), theme = ttheme_minimal())

grid.arrange(fl.cor.heatmap, t, nrow=2)
dev.off()
```
Observations:
* Q30 & ClusterPF seem to have a large positive impact on the percentage of mapped reads, And the Singletons percentage, which are reads which are unmapped but their mate is not.
§
* Phasing & Prephasing seem to negativly impact the mapped percentage

Metrics that could have interactions:
  MappedPercentage
  ProperPairPCT
  SingleTonsPass
  SingletonsPCT
  MateOnDiffChromosomeLowPass
  MateOnDiffChromosomeLowPass
  


## 2.2 List

Starting Metrics: 
  A260_230
  A260_280

Metrics that could have interactions: Interop
  Aligned
  Intensity
  Q30
  Phasing
  PrePhasing
  ClustersPF
  ClusterDensity
  
Metrics that could have interactions Post-bam:
  Chimeras
  Adapter sequences
  indels
  mismatch rate/ error rate (are almost equal, we use mismatch rate for now)
  median mismatch rate
  OnBaitVSselected
  BaitTerritory
  MeanBaitCoverage
  MedianTargetCoverage
  MeanTargetCoverage
  ExtMapQPct
  Fold80 base penalty
  FoldEnrichment
  ZeroCVGtargetsPercentage
  TargetBasesPct20X
  HsPenalty20X
  HetSNPsensitivity
  HetSNPQ
  MeanSize
  MedianSize
  MappedPercentage
  ProperPairPCT
  SingleTonsPass
  SingletonsPCT
  MateOnDiffChromosomeLowPass
  MateOnDiffChromosomeLowPass
  FractionDuplicates
  

# 3. Modeling using Gradient Boosting

```{r}
library(tidyverse)
library(caret)
library(xgboost)
# Removal of identification data and metrics with similar correlations
# model.data <- complete.data.edit %>% select(-c(SampleName, UniqueID, RunID.x, Number, Flowcell, Sequencer, Date, ID, flowcell, project, capturingKit, RunID.y, W10, W20, W30, W40, W50, W60, W70, W80, W90, W99, TargetBasesPct10X, TargetBasesPct100X, TargetBasesPct1X, TargetBasesPct2X, TargetBasesPct30X, TargetBasesPct40X, TargetBasesPct50X, PFHQErrorRate, TotalPass, SecondaryPass, DuplicatePass, MappedPass, PairedSeqPass, Read1Pass, PoperPairPass, SelfAndMatePass, SingletonsPass, MateOnDiffChromosomeLowPass, MateOnDiffChromosomeHighPass, MaxSize, MedianAbsoluteDeviation, HsPenalty100X, HsPenalty10X, HsPenalty30X, HsPenalty40X, HsPenalty50X))

model.data.all2 <- complete.data.edit %>% select(A260_230, A260_280, Aligned, Intensity, Average_Q30, Phasing, PrePhasing, ClusterPF, ClusterDensity, ChimerasPercentage, AdapterPercentage, PFindelRate, PFmismatchRate, PFHQmedianMismatches, OnBaitVSselected, MeanBaitCoverage, MedianTargetCoverage, MeanTargetCoverage, ExcMapQPct, Fold80BasePenalty, FoldEnrichment, ZeroCVGtargetsPercentage, TargetBasesPct20X, HsPenalty20X, HetSNPsensitivity, StrandBalance, MeanSize, MedianSize, MappedPercentage, ProperPairPCT, SingletonsPercentage, Used, Instrument)

model.data2 <- model.data.all2 %>% select(-c(A260_230, A260_280, Aligned, Intensity, Average_Q30, Phasing, PrePhasing, ClusterPF, ClusterDensity))
model.data2$FractionDuplicates <- complete.data.edit$PFuniqueReads / complete.data.edit$TotalReads.x # Additional metric of interest: Fraciton of duplicates

model.data2.NExtSeq <- model.data2[model.data2$Instrument == "NextSeq",]
model.data2.NExtSeq <- model.data2.NExtSeq %>% select(-Instrument)

model.data2.MiSeq <- model.data2[model.data2$Instrument == "MiSeq",]
model.data2.MiSeq <- model.data2.MiSeq %>% select(-Instrument)
```

```{r}
set.seed(163) ## for reproducability
training.data <- model.data2.NExtSeq$Used %>% 
  createDataPartition(p = 0.8, list = FALSE)

train.data  <- model.data2.NExtSeq[training.data, ]
test.data <- model.data2.NExtSeq[-training.data, ]

set.seed(163) ## for reproducability
training.data.miseq <- model.data2.MiSeq$Used %>% 
  createDataPartition(p = 0.8, list = FALSE)

train.data.mi  <- model.data2.MiSeq[training.data.miseq, ]
test.data.mi <- model.data2.MiSeq[-training.data.miseq, ]

```

```{r}
set.seed(163)
tune_grid2 <- expand.grid(
  nrounds = seq(from = 50, to = 1000, by = 50),
  eta = 0.3,
  max_depth = c(2,3,4),
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight = c(1,2,3),
  subsample = 1
)

#Fit the model on the training set
set.seed(163)
model3 <- caret::train(
   Used ~., data = train.data, method = "xgbTree",
   trControl = trainControl("cv", number = 10),
   tune_grid = tune_grid2
   )
 # Best tuning parameter
model3$bestTune
```

```{r}
set.seed(163)
tune_grid2 <- expand.grid(
  nrounds = seq(from = 50, to = 1000, by = 50),
  eta = 0.3,
  max_depth = c(2,3,4),
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight = c(1,2,3),
  subsample = 1
)

#Fit the model on the training set
set.seed(163)
model3.mi <- caret::train(
   Used ~., data = train.data.mi, method = "xgbTree",
   trControl = trainControl("cv", number = 10),
   tune_grid = tune_grid2
   )
 # Best tuning parameter
model3.mi$bestTune
```


```{r}
model3pred <- predict (model3.mi,test.data)
confusionMatrix (model3pred,  test.data$Used)
imp <- varImp(model3.mi)$importance

imp$metric <- rownames(imp)
imp$metric <- factor(imp$metric, levels = imp$metric[order(imp$Overall)])

imp <- varImp(model3.mi)$importance

imp$metric <- rownames(imp)
imp$metric <- factor(imp$metric, levels = imp$metric[order(imp$Overall)])
imp$Invluence_level <- ifelse(imp$Overall == 100 , "100%", 
                              ifelse(imp$Overall > 75 , "75 - 99 %",
                              ifelse(imp$Overall > 50 , "50 - 74 %",
                              ifelse(imp$Overall  >25 , "25 - 49 %", "< 25 %"))))

imp$Invluence_level <- factor(imp$Invluence_level, levels = c("100%", "75 - 99 %", "50 - 74 %", "25 - 49 %",  "< 25 %"))

library(ROCR)
predicted.classes <- model3.mi %>% predict(test.data)

accuracy <- (sum(predicted.classes == test.data$Used)/nrow(test.data)) * 100

test.data$predicted <- predicted.classes
 
d <- table(test.data$Used, test.data$predicted)

a<- as.numeric(test.data$predicted)

b<- as.numeric(test.data$Used)

pred <- prediction(a, b)
auc.tmp <- performance(pred,"auc")
auc <- as.numeric(auc.tmp@y.values)
FPR <- signif(d[1,2]/sum(d[,1]), digits = 2)
FPR
FNR <- signif(d[2,1]/sum(d[2,]), digits = 2)
FNR
subt <- paste0("in MiSeq Sequencers, ","Accuracy: ", signif(accuracy, digits = 3), "%", " FPR: ", FPR, " FNR: ", FNR)

p1 <- ggplot(imp, aes(x=metric, y=Overall, fill=Invluence_level)) + geom_bar(stat = "identity")  + coord_flip() + ylab("Level of importance (%)") + xlab("Metric in model") + ggtitle("Feature invluence for the model to classify lower quality samples", subtitle = subt) + scale_fill_manual(values=c("green", "cyan", "blue", "orange", "red"))

p1


```

```{r}
# reduce skewedness
model.data2.not.reinserted.mi <- model.data2.MiSeq[model.data2.MiSeq$Used == "Not Reinserted",]
model.data2.reinserted.mi <- model.data2.MiSeq[model.data2.MiSeq$Used == "Reinserted",]

nrow(model.data2.reinserted.mi)
nrow(model.data2.not.reinserted.mi)
set.seed(163)
model.data2.not.reinserted.sample.mi <- model.data2.not.reinserted.mi[sample(nrow(model.data2.not.reinserted.mi), size = nrow(model.data2.reinserted.mi)),]

model.data.equal.mi <- rbind(model.data2.reinserted.mi, model.data2.not.reinserted.sample.mi)
set.seed(163) ## for reproducability
training.data2.mi <- model.data.equal.mi$Used %>% 
  createDataPartition(p = 0.8, list = FALSE)

train.data2.mi  <- model.data.equal.mi[training.data2.mi, ]
test.data2.mi <- model.data.equal.mi[-training.data2.mi, ]

# Fit the model on the training set
set.seed(163)
trCtr <- trainControl("cv", number = 10)

set.seed(163)
model4.mi <- train(
  Used ~., data = train.data2.mi, method = "xgbTree",
  trControl = trCtr,
  )
# Best tuning parameter
model4$bestTune
```

```{r}
  model4pred.mi <- predict (model4.mi,test.data2.mi)
confusionMatrix (model4pred.mi, test.data2.mi$Used)
imp <- varImp(model4.mi)$importance

imp$metric <- rownames(imp)
imp$metric <- factor(imp$metric, levels = imp$metric[order(imp$Overall)])

imp <- varImp(model4.mi)$importance

imp$metric <- rownames(imp)
imp$metric <- factor(imp$metric, levels = imp$metric[order(imp$Overall)])
imp$Invluence_level <- ifelse(imp$Overall == 100 , "100%", 
                              ifelse(imp$Overall > 75 , "75 - 99 %",
                              ifelse(imp$Overall > 50 , "50 - 74 %",
                              ifelse(imp$Overall  >25 , "25 - 49 %", "< 25 %"))))

imp$Invluence_level <- factor(imp$Invluence_level, levels = c("100%", "75 - 99 %", "50 - 74 %", "25 - 49 %",  "< 25 %"))

library(ROCR)
predicted.classes <- model4.mi %>% predict(test.data2.mi)

accuracy <- (sum(predicted.classes == test.data2.mi$Used)/nrow(test.data2.mi)) * 100

test.data2.mi$predicted <- predicted.classes
 
d <- table(test.data$Used, test.data$predicted)

a<- as.numeric(test.data2.mi$predicted)

b<- as.numeric(test.data2.mi$Used)

pred <- prediction(a, b)
auc.tmp <- performance(pred,"auc")
auc <- as.numeric(auc.tmp@y.values)
FPR <- signif(d[1,2]/sum(d[,1]), digits = 2)
FPR
FNR <- signif(d[2,1]/sum(d[2,]), digits = 2)
FNR
subt <- paste0("Accuracy: ", signif(accuracy, digits = 3), "%", " FPR: ", FPR, " FNR: ", FNR)

p2 <- ggplot(imp, aes(x=metric, y=Overall, fill=Invluence_level)) + geom_bar(stat = "identity")  + coord_flip() + ylab("Level of importance (%)") + xlab("Metric in model") + ggtitle("Metric importance acording to the xdgboost model", subtitle = subt) + scale_fill_manual(values=c("green", "cyan", "blue", "orange", "red"))

library(gridExtra)

ggsave("Model_performance1_MISEQ.png", 
       plot = p1, 
       dpi = 300)
ggsave("Model_performance2_MISEQ.png", 
       plot = p2, 
       dpi = 300)

```

```{r}
# reduce skewedness
model.data2.not.reinserted <- model.data2.NExtSeq[model.data2.NExtSeq$Used == "Not Reinserted",]
model.data2.reinserted <- model.data2.NExtSeq[model.data2.NExtSeq$Used == "Reinserted",]

nrow(model.data2.reinserted)
nrow(model.data2.not.reinserted)
set.seed(163)
model.data2.not.reinserted.sample <- model.data2.not.reinserted[sample(nrow(model.data2.not.reinserted), size = nrow(model.data2.reinserted)),]

model.data.equal <- rbind(model.data2.reinserted, model.data2.not.reinserted.sample)
set.seed(163) ## for reproducability
training.data2 <- model.data.equal$Used %>% 
  createDataPartition(p = 0.8, list = FALSE)

train.data2  <- model.data.equal[training.data2, ]
test.data2 <- model.data.equal[-training.data2, ]

```

```{r}
# Fit the model on the training set
set.seed(163)
trCtr <- trainControl("cv", number = 10)

set.seed(163)
model5 <- train(
  Used ~., data = train.data2, method = "xgbTree",
  trControl = trCtr,
  )
# Best tuning parameter
model5$bestTune
```

```{r}
model5pred <- predict (model5,test.data2)
confusionMatrix (model5pred,  test.data2$Used)
imp2 <- varImp(model5)$importance

imp2$metric <- rownames(imp2)
imp2$metric <- factor(imp2$metric, levels = imp2$metric[order(imp2$Overall)])
imp2$Invluence_level <- ifelse(imp2$Overall == 100 , "100%", 
                              ifelse(imp2$Overall > 75 , "75 - 99 %",
                              ifelse(imp2$Overall > 50 , "50 - 74 %",
                              ifelse(imp2$Overall  >25 , "25 - 49 %", "< 25 %"))))

imp2$Invluence_level <- factor(imp2$Invluence_level, levels = c("100%", "75 - 99 %", "50 - 74 %", "25 - 49 %",  "< 25 %"))

library(ROCR)
 predicted.classes <- model5 %>% predict(test.data2)
 
accuracy <- (sum(predicted.classes == test.data2$Used)/nrow(test.data2)) * 100

test.data2$predicted <- predicted.classes
 
d <- table(test.data2$Used, test.data2$predicted)
d
a<- as.numeric(test.data2$predicted)

b<- as.numeric(test.data2$Used)

pred <- prediction(a, b)
auc.tmp <- performance(pred,"auc")
auc <- as.numeric(auc.tmp@y.values)
FPR <- signif(d[1,2]/sum(d[,1]), digits = 2)
FPR
FNR <- signif(d[2,1]/sum(d[2,]), digits = 2)
FNR
subt <- paste0("In Next seq machines","Accuracy: ", signif(accuracy, digits = 3), "%", " FPR: ", FPR, " FNR: ", FNR)

p <- ggplot(imp2, aes(x=metric, y=Overall, fill=Invluence_level)) + geom_bar(stat = "identity") + coord_flip() + ylab("Level of importance (%)") + xlab("Metric in model") + ggtitle("Metric importance acording to the xdgboost model", subtitle = subt) + scale_fill_manual(values=c("green", "cyan", "blue", "orange", "red"))


ggsave("Model_performance2.png", 
       plot = p, 
       dpi = 300)

p

```

In combination with these results and judgment of interesting metrics the following list of 14 metrics was created: 

* OnBaitVsSelected - larges invluencer, might indicate lesser bait performance.
* MeanTargetCoverage - high invluencer, and if we want target coverage to remain high, interesting to look at
* Fold80BasePenalty - high invluencer, describes the penalty required to achieve a certain coverage for targets with a coverage of 1
* HetSNPsensitivity - high invluencer and interesting as the it mught be usefull to know that the sensitivity/likelyhood of detecting SNP's in heterozyous pairs gous down.

* ChimerasPercentage - high invluencer, and interesting as it could indicate contamination in a sample

* ExcMapQpct - high invluencer, could be interesting to know if the fraction of bases that were filtered out becouse of lower quality
* PFmismatchRate - moderate invluencer, and we want this to remain lower.
* FractionDuplicates - moderate invluencer, Fraction of duplicates we want this to decrease, usefull to assess
* MeanSize - moderate invluencer, ultimatly we want the insert size to increase

* PF indel Rate, moderate invluencer, could be usefull to know if there is any effect on the amount of insertions/deletions in a read.

* HSpenalty20X
* MeanBaitCoverage
* SingletonsPErcentage
* MedianSize
* TargetBasesPct20X, less invluential, but is the coverage used for quality assesment in the current proccess, this has to remain high


Metrics excluded:
* Mapped Percentage
* Median target coverage
* PFHQmedianMismatches
* Adapter PErcentage
* StrandBalance, altough a high invluencer, no real interest in quality metrics
* ProperPairPCT, ultimatly, it is not clear what this metric represents, so its not usefull in later analysis

# 4. Testing the data differentces

```{r}
library(dplyr)
complete.data.edit$FractionDuplicates <- (1 - complete.data.edit$PFuniqueReads/complete.data.edit$TotalReads.x)

metric.list <- complete.data.edit %>% select(UniqueID,A260_280, A260_230, Intensity, PrePhasing, Phasing, ClusterDensity, Average_Q30, ClusterPF, ChimerasPercentage, FoldEnrichment, TargetBasesPct20X, OnBaitVSselected, PFmismatchRate, HetSNPsensitivity, MeanTargetCoverage, FractionDuplicates, PFindelRate, MeanSize, ExcMapQPct, SingletonsPercentage, StrandBalance, HsPenalty20X, Instrument)



metric.list[metric.list$Instrument == "NB500917R",]$Instrument <- "NextSeq"

metric.list$Instrument <- droplevels(metric.list$Instrument)

metric.list.NextSeq <- metric.list[metric.list$Instrument == "NextSeq",]
metric.list.MiSeq <- metric.list[metric.list$Instrument == "MiSeq",]

metric.list.MiSeq <- metric.list.MiSeq[metric.list.MiSeq$Intensity < 5000, ] # filter incorrectly labled miseq machines
metric.list.NextSeq <- metric.list.NextSeq[metric.list.NextSeq$Intensity > 5000, ] # filter incorrectly labled Next seq machines
metric.list.NextSeq <- metric.list.NextSeq %>% select(!Instrument) 
metric.list.MiSeq <- metric.list.MiSeq%>% select(!Instrument)
```

## Next seq machines
```{r}
library(dplyr)
library(reshape2)
library(ggplot2)
library(scales)

metric.list.NextSeq$threshold <- unlist(lapply(metric.list.NextSeq$A260_280, function(x) {
  val <- x
  if (val > 2.0) {
    return("High")
  }
  if (val < 1.8) {
    return("Low")
  }
  return("Norm")
}))

remove_outliers_high <- function(x, na.rm = TRUE, ...) {
  qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm, ...)
  H <- 1.5 * IQR(x, na.rm = na.rm)
  y <- x
  y[x > (qnt[2] + H)] <- NA
  y
}
remove_outliers_low <- function(x, na.rm = TRUE, ...) {
  qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm, ...)
  H <- 1.5 * IQR(x, na.rm = na.rm)
  y <- x
  y[x < (qnt[1] - H)] <- NA
  y
}

remove_outliers_norm <- function(x, na.rm = TRUE, ...) {
  qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm, ...)
  H <- 1.5 * IQR(x, na.rm = na.rm)
  y <- x
  y[x < (qnt[1] - H)] <- NA
  y[x > (qnt[2] + H)] <- NA
  y
}

head(metric.list.NextSeq)

prebam <- c(4:9)
postbam <- c(10:23)

metric.list.NextSeq.outlier <- metric.list.NextSeq


 metric.list.NextSeq.outlier[metric.list.NextSeq$threshold == "High",][c(2, prebam, postbam)]<- as.data.frame(apply(metric.list.NextSeq[metric.list.NextSeq$threshold == "High",][c(2,prebam,postbam)], 2, remove_outliers_norm))

metric.list.NextSeq.outlier[metric.list.NextSeq$threshold == "Norm",][c(2,prebam,postbam)] <- as.data.frame(apply(metric.list.NextSeq[metric.list.NextSeq$threshold == "Norm",][c(2,prebam, postbam)], 2, remove_outliers_norm))


metric.list.NextSeq.outlier[metric.list.NextSeq$threshold == "Low",][c(2,prebam,postbam)] <- as.data.frame(apply(metric.list.NextSeq[metric.list.NextSeq$threshold == "Low",][c(2,prebam,postbam)], 2, remove_outliers_norm))

metric.list.NextSeq.scaled <- na.omit(metric.list.NextSeq.outlier)
metric.list.NextSeq.scaled
metric.list.NextSeq.scaled[c(2:(ncol(metric.list.NextSeq.scaled) -1))] <- as.data.frame(apply(metric.list.NextSeq.scaled[c(2,prebam,postbam)], 2, function(x) {
  rescale(x, to=c(-1,1))
}))

metric.list.NextSeq.scaled$threshold <- factor(metric.list.NextSeq.scaled$threshold, levels = c("High", "Norm", "Low"))
df_melted = melt(metric.list.NextSeq.scaled[c(1,2,prebam,postbam, ncol(metric.list.NextSeq.scaled))], id.vars = c('UniqueID', 'threshold'), na.rm = TRUE)
df_melted
mean.lines <- ggplot(df_melted, aes(x = variable, y = value, fill = threshold)) +
  geom_boxplot(alpha = 0.5) +
  scale_fill_manual(values=c("red", "green", "blue"), name = "Threshold", labels = c("Above", "Between", "Below")) +
  ggtitle("Mean scaled metric change", subtitle = "compared to the 260:280 threshold limits (NextSeq)") + 
  ylab("Change from center") + 
  theme(axis.text.x=element_text(angle = 90, size = 15),
        plot.title = element_text(size = 20),
        plot.subtitle = element_text(size = 15),
        legend.text = element_text(size = 10),
        axis.text.y = element_text(size = 12),
        axis.title.y = element_text(size = 15 )) 

mean.lines

ggsave(
  "NextSeq_threshold_change.png",
  plot = mean.lines,
  limitsize = TRUE,
  scale = 1,
  width = 14,
  height = 7
)


```
* Intensity seems to differ
* Prephasing seems to differ
* Mismatch rate seems to differ
* Median target coverage seems to differ
* Mean insert Size seems to differ
* Number of aligned reads seem to differ
* Fraction of duplicates seem to differ

```{r}
summary(metric.list.NextSeq$A260_280)
summary(metric.list.NextSeq$MeanBaitCoverage)
```

```{r}
library(dplyr)
get.significance <- function(p) {
  chr.p <- "Not significant"
    if (p < .05) {
        chr.p <- "P<.05"
      }
      if (p < .01) {
        chr.p <- "P<.01"
      }
      if (p < .001) {
        chr.p <- "P<.001"
      }
      if (p < .0001) {
        chr.p <- "P<.0001"
      }
  return(chr.p)
}

perform_t.tests <- function(metrics, test.high=T, test.low=T) {
  ThresholdTests.high <- data.frame(Metric=character(),
                   Significance=double(), 
                   Significant=logical(),
                   Difference=character(), 
                   stringsAsFactors=FALSE)
  
  ThresholdTests.low <- data.frame(Metric=character(),
                   Significance=double(), 
                   Significant=logical(),
                   Difference=character(), 
                   stringsAsFactors=FALSE)
  
  low <- metrics[metrics$threshold == "Low",]
  normal <- metrics[metrics$threshold == "Norm",]
  high <- metrics[metrics$threshold == "High",]
  
  low <-low %>% select(!threshold)
  normal <- normal %>% select(!threshold)
  high <-high %>% select(!threshold)
  for (name in colnames(normal)) {
  
    #get values per group from column
    dat.norm <- as.matrix(normal[name])[,1]
    dat.low <- as.matrix(low[name][1])[,1]
    dat.high <-as.matrix(high[name][1])[,1]
    if (test.high){
      #preform high threshold vs normal test
      t <-t.test(dat.norm, dat.high, paired = F)
    
      #add to table
      ThresholdTests.high[nrow(ThresholdTests.high) + 1,] <- c(name,t$p.value, t$p.value < 0.05, mean(dat.high) - mean(dat.norm))
    }
    if (test.low){
    #perform low threshold vs normal rest
    t <-t.test(normal[name], low[name], paired = F)
    
    #add to table
    ThresholdTests.low[nrow(ThresholdTests.low) + 1,] <- c(name,t$p.value, t$p.value < 0.05,  mean(dat.low) - mean(dat.norm))
    }
  }
  if (test.high){
    if (test.low){
      l <- list(
      ThresholdTests.high,
      ThresholdTests.low
        )
      return(l)
    }else {
      return(ThresholdTests.high)
    }
  } else {
      return(ThresholdTests.low)
    }
}

res <- perform_t.tests(metric.list.NextSeq[-c(1:3)])

res[[1]][res[[1]]$Significant == T,]
res[[2]][res[[2]]$Significant == T,]

```



```{r}

library(dplyr)
library(reshape2)
library(ggplot2)
library(scales)

metric.list.MiSeq$threshold <- unlist(lapply(metric.list.MiSeq$A260_280, function(x) {
  val <- x
  if (val > 2.0) {
    return("High")
  }
  if (val < 1.8) {
    return("Low")
  }
  return("Norm")
}))

remove_outliers_high <- function(x, na.rm = TRUE, ...) {
  qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm, ...)
  H <- 1.5 * IQR(x, na.rm = na.rm)
  y <- x
  y[x > (qnt[2] + H)] <- NA
  y
}
remove_outliers_low <- function(x, na.rm = TRUE, ...) {
  qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm, ...)
  H <- 1.5 * IQR(x, na.rm = na.rm)
  y <- x
  y[x < (qnt[1] - H)] <- NA
  y
}

remove_outliers_norm <- function(x, na.rm = TRUE, ...) {
  qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm, ...)
  H <- 1.5 * IQR(x, na.rm = na.rm)
  y <- x
  y[x < (qnt[1] - H)] <- NA
  y[x > (qnt[2] + H)] <- NA
  y
}

head(metric.list.MiSeq)

prebam <- c(4:9)
postbam <- c(10:23)

metric.list.MiSeq.outlier <- metric.list.MiSeq
metric.list.MiSeq.outlier[metric.list.MiSeq$threshold == "High",][c(2,prebam,postbam)] <- as.data.frame(apply(metric.list.MiSeq[metric.list.MiSeq$threshold == "High",][c(2,prebam,postbam)], 2, remove_outliers_norm))

metric.list.MiSeq.outlier[metric.list.MiSeq$threshold == "Norm",][c(2,prebam,postbam)] <- as.data.frame(apply(metric.list.MiSeq[metric.list.MiSeq$threshold == "Norm",][c(2,prebam, postbam)], 2, remove_outliers_norm))


metric.list.MiSeq.outlier[metric.list.MiSeq$threshold == "Low",][c(2,prebam,postbam)] <- as.data.frame(apply(metric.list.MiSeq[metric.list.MiSeq$threshold == "Low",][c(2,prebam,postbam)], 2, remove_outliers_norm))

metric.list.MiSeq.scaled <- na.omit(metric.list.MiSeq.outlier)
metric.list.MiSeq.scaled
metric.list.MiSeq.scaled[c(2:(ncol(metric.list.MiSeq.scaled) -1))] <- as.data.frame(apply(metric.list.MiSeq.scaled[c(2,prebam,postbam)], 2, function(x) {
  rescale(x, to=c(-1,1))
}))

metric.list.MiSeq.scaled$threshold <- factor(metric.list.MiSeq.scaled$threshold, levels = c("High", "Norm", "Low"))
df_melted = melt(metric.list.MiSeq.scaled[c(1,2,prebam,postbam, ncol(metric.list.MiSeq.scaled))], id.vars = c('UniqueID', 'threshold'), na.rm = TRUE)
df_melted
mean.lines <- ggplot(df_melted, aes(x = variable, y = value, fill = threshold)) +
  geom_boxplot(alpha = 0.5) +
  scale_fill_manual(values=c("red", "green", "blue"), name = "Threshold", labels = c("Above", "Between", "Below")) +
  ggtitle("Mean scaled metric change", subtitle = "compared to the 260:280 threshold limits (MiSeq)") + 
  ylab("Change from center") + 
  theme(axis.text.x=element_text(angle = 90, size = 15),
        plot.title = element_text(size = 20),
        plot.subtitle = element_text(size = 15),
        legend.text = element_text(size = 10),
        axis.text.y = element_text(size = 12),
        axis.title.y = element_text(size = 15 )) 

mean.lines

ggsave(
  "MiSeq_threshold_change.png",
  plot = mean.lines,
  limitsize = TRUE,
  scale = 1,
  width = 14,
  height = 7
)


```

```{r}
res <- perform_t.tests(metric.list.MiSeq[-c(1:3)])

res[[1]][res[[1]]$Significant == T,]
res[[2]][res[[2]]$Significant == T,]

```


## thresholds for 260:230
###NExt Seq
```{r}
metric.list.NextSeq$threshold <- unlist(lapply(metric.list.NextSeq$A260_230, function(x) {
  val <- x
  if (val < 1.5) {
    return("Low")
  }
  return("Norm")
}))

metric.list.NextSeq.outlier <- metric.list.NextSeq
metric.list.NextSeq.outlier[metric.list.NextSeq$threshold == "High",][c(3,prebam,postbam)] <- as.data.frame(apply(metric.list.NextSeq[metric.list.NextSeq$threshold == "High",][c(3,prebam,postbam)], 2, remove_outliers_norm))

metric.list.NextSeq.outlier[metric.list.NextSeq$threshold == "Norm",][c(3,prebam,postbam)] <- as.data.frame(apply(metric.list.NextSeq[metric.list.NextSeq$threshold == "Norm",][c(3,prebam,postbam)], 2, remove_outliers_norm))


metric.list.NextSeq.outlier[metric.list.NextSeq$threshold == "Low",][c(3,prebam,postbam)] <- as.data.frame(apply(metric.list.NextSeq[metric.list.NextSeq$threshold == "Low",][c(3,prebam,postbam)], 2, remove_outliers_norm))

metric.list.NextSeq.scaled <- na.omit(metric.list.NextSeq.outlier)
metric.list.NextSeq.scaled[c(3:(ncol(metric.list.MiSeq.scaled) -1))] <- as.data.frame(apply(metric.list.NextSeq.scaled[c(3,prebam,postbam)], 2, function(x) {
  rescale(x, to=c(-1,1))
}))

metric.list.NextSeq.scaled$threshold <- factor(metric.list.NextSeq.scaled$threshold, levels = c("Norm", "Low"))
df_melted = melt(metric.list.NextSeq.scaled[-2], id.vars = c('UniqueID', 'threshold'), na.rm = TRUE)
df_melted
mean.lines <- ggplot(df_melted, aes(x = variable, y = value, fill = threshold)) +
  geom_boxplot(alpha = 0.5) +
  scale_fill_manual(values=c("green", "blue"), name = "Threshold", labels = c("Between", "Below")) +
  ggtitle("Mean scaled metric change", subtitle = "compared to the 260:230 threshold limits (NextSeq)") + 
  ylab("Change from center") + 
  theme(axis.text.x=element_text(angle = 90, size = 15),
        plot.title = element_text(size = 20),
        plot.subtitle = element_text(size = 15),
        legend.text = element_text(size = 10),
        axis.text.y = element_text(size = 12),
        axis.title.y = element_text(size = 15 )) 

mean.lines

ggsave(
  "NextSeq_threshold260230_change.png",
  plot = mean.lines,
  limitsize = TRUE,
  scale = 1,
  width = 14,
  height = 7
)
```

```{r}
res <- perform_t.tests(metric.list.NextSeq[-c(1:3)], test.high = F)

res[res$Significant == T,]

```

##MiSEQ
```{r}
metric.list.MiSeq$threshold <- unlist(lapply(metric.list.MiSeq$A260_230, function(x) {
  val <- x
  if (val < 1.5) {
    return("Low")
  }
  return("Norm")
}))

metric.list.MiSeq.outlier <- metric.list.MiSeq
metric.list.MiSeq.outlier[metric.list.MiSeq$threshold == "High",][c(3,prebam,postbam)] <- as.data.frame(apply(metric.list.MiSeq[metric.list.MiSeq$threshold == "High",][c(3,prebam,postbam)], 2, remove_outliers_norm))

metric.list.MiSeq.outlier[metric.list.MiSeq$threshold == "Norm",][c(3,prebam,postbam)] <- as.data.frame(apply(metric.list.MiSeq[metric.list.MiSeq$threshold == "Norm",][c(3,prebam,postbam)], 2, remove_outliers_norm))


metric.list.MiSeq.outlier[metric.list.MiSeq$threshold == "Low",][c(3,prebam,postbam)] <- as.data.frame(apply(metric.list.MiSeq[metric.list.MiSeq$threshold == "Low",][c(3,prebam,postbam)], 2, remove_outliers_norm))

metric.list.MiSeq.scaled <- na.omit(metric.list.MiSeq.outlier)
metric.list.MiSeq.scaled[c(3:(ncol(metric.list.MiSeq.scaled) -1))] <- as.data.frame(apply(metric.list.MiSeq.scaled[c(3,prebam,postbam)], 2, function(x) {
  rescale(x, to=c(-1,1))
}))

metric.list.MiSeq.scaled$threshold <- factor(metric.list.MiSeq.scaled$threshold, levels = c("Norm", "Low"))
df_melted = melt(metric.list.MiSeq.scaled[-2], id.vars = c('UniqueID', 'threshold'), na.rm = TRUE)
df_melted
mean.lines <- ggplot(df_melted, aes(x = variable, y = value, fill = threshold)) +
  geom_boxplot(alpha = 0.5) +
  scale_fill_manual(values=c("green", "blue"), name = "Threshold", labels = c("Between", "Below")) +
  ggtitle("Mean scaled metric change", subtitle = "compared to the 260:230 threshold limits (MiSeq)") + 
  ylab("Change from center") + 
  theme(axis.text.x=element_text(angle = 90, size = 15),
        plot.title = element_text(size = 20),
        plot.subtitle = element_text(size = 15),
        legend.text = element_text(size = 10),
        axis.text.y = element_text(size = 12),
        axis.title.y = element_text(size = 15 )) 

mean.lines

ggsave(
  "MiSeq_threshold260230_change.png",
  plot = mean.lines,
  limitsize = TRUE,
  scale = 1,
  width = 14,
  height = 7
)
```

```{r}
res <- perform_t.tests(metric.list.MiSeq[-c(1:3)], test.high = F)

res[res$Significant == T,]

```

## Sequencing Intensity

### NextSeq
```{r}

sd.Intens <- sd(metric.list.NextSeq$Intensity)
me.intens <- mean(metric.list.NextSeq$Intensity)
metric.list.NextSeq$threshold <- unlist(lapply(metric.list.NextSeq$Intensity, function(x, th=sd.Intens, center=me.intens) {
  val <- x
  if (val > (center + (th* 2))) {
    return("High")
  }
  if (val < (center - (th*2))) {
    return("Low")
  }
  return("Norm")
}))






metric.list.NextSeq.scaled <- na.omit(metric.list.NextSeq.outlier)
metric.list.NextSeq.scaled[c(prebam,postbam)] <- as.data.frame(apply(metric.list.NextSeq.scaled[c(prebam,postbam)], 2, function(x) {
  rescale(x, to=c(-1,1))
}))

metric.list.NextSeq.scaled$threshold <- factor(metric.list.NextSeq.scaled$threshold, levels = c("High", "Norm", "Low"))
df_melted = melt(metric.list.NextSeq.scaled[-c(2, 3)], id.vars = c('UniqueID', 'threshold'), na.rm = TRUE)
df_melted
mean.lines <- ggplot(df_melted, aes(x = variable, y = value, fill = threshold)) +
  geom_boxplot(alpha = 0.5) +
  scale_fill_manual(values=c("red", "green", "blue"), name = "Threshold", labels = c("Above", "Between", "Below")) +
  ggtitle("Mean scaled metric change", subtitle = "compared to the Intensity thresholds 2 * SD (NextSeq)") + 
  ylab("Change from center") + 
  theme(axis.text.x=element_text(angle = 90, size = 15),
        plot.title = element_text(size = 20),
        plot.subtitle = element_text(size = 15),
        legend.text = element_text(size = 10),
        axis.text.y = element_text(size = 12),
        axis.title.y = element_text(size = 15 )) 

mean.lines

ggsave(
  "NextSeq_thresholdIntensity_change.png",
  plot = mean.lines,
  limitsize = TRUE,
  scale = 1,
  width = 14,
  height = 7
)
```

```{r}
res <- perform_t.tests(metric.list.NextSeq[-c(1,2,3,4)], test.low = F)

res[res$Significant == T, ]
```

### MiSEQ
```{r}

sd.Intens <- sd(metric.list.MiSeq$Intensity)
me.intens <- mean(metric.list.MiSeq$Intensity)
metric.list.MiSeq$threshold <- unlist(lapply(metric.list.MiSeq$Intensity, function(x, th=sd.Intens, center=me.intens) {
  val <- x
  if (val > (center + (th* 2))) {
    return("High")
  }
  if (val < (center - (th*2))) {
    return("Low")
  }
  return("Norm")
}))


metric.list.MiSeq.scaled <- na.omit(metric.list.MiSeq.outlier)
metric.list.MiSeq.scaled[c(prebam,postbam)] <- as.data.frame(apply(metric.list.MiSeq.scaled[c(prebam,postbam)], 2, function(x) {
  rescale(x, to=c(-1,1))
}))

metric.list.MiSeq.scaled$threshold <- factor(metric.list.MiSeq.scaled$threshold, levels = c("High", "Norm", "Low"))
df_melted = melt(metric.list.MiSeq.scaled[-c(2, 3)], id.vars = c('UniqueID', 'threshold'), na.rm = TRUE)
df_melted
mean.lines <- ggplot(df_melted, aes(x = variable, y = value, fill = threshold)) +
  geom_boxplot(alpha = 0.5) +
  scale_fill_manual(values=c("red", "green", "blue"), name = "Threshold", labels = c("Above", "Between", "Below")) +
  ggtitle("Mean scaled metric change", subtitle = "compared to the Intensity thresholds 2 * SD (MiSeq)") + 
  ylab("Change from center") + 
  theme(axis.text.x=element_text(angle = 90, size = 15),
        plot.title = element_text(size = 20),
        plot.subtitle = element_text(size = 15),
        legend.text = element_text(size = 10),
        axis.text.y = element_text(size = 12),
        axis.title.y = element_text(size = 15 )) 

mean.lines

ggsave(
  "MiSeq_thresholdIntensity_change.png",
  plot = mean.lines,
  limitsize = TRUE,
  scale = 1,
  width = 14,
  height = 7
)
```


```{r}
# metric.list.MiSeq[-c(1,2,3,4)]
# res <- perform_t.tests(metric.list.MiSeq[-c(1,2,3,4)], test.low = F)
# 
# res[res$Significant == T, ]
```
Cannot perform difference tests as the miseq intensitys do not differ enough
## PrePhasing
### NextSeq
```{r}

me.prephasing <- (median(metric.list.NextSeq$PrePhasing) + sd(metric.list.NextSeq$PrePhasing) * 2)
metric.list.NextSeq$threshold <- unlist(lapply(metric.list.NextSeq$PrePhasing, function(x, center=me.prephasing) {
  val <- x
  if (val > center) {
    return("High")
  }
  return("Norm")
}))

metric.list.NextSeq.outlier <- metric.list.NextSeq
metric.list.NextSeq.outlier[metric.list.NextSeq$threshold == "High",][c(prebam,postbam)] <- as.data.frame(apply(metric.list.NextSeq[metric.list.NextSeq$threshold == "High",][c(prebam,postbam)], 2, remove_outliers_norm))

metric.list.NextSeq.outlier[metric.list.NextSeq$threshold == "Norm",][c(prebam,postbam)] <- as.data.frame(apply(metric.list.NextSeq[metric.list.NextSeq$threshold == "Norm",][c(prebam,postbam)], 2, remove_outliers_norm))


metric.list.NextSeq.outlier[metric.list.NextSeq$threshold == "Low",][c(prebam,postbam)] <- as.data.frame(apply(metric.list.NextSeq[metric.list.NextSeq$threshold == "Low",][c(prebam,postbam)], 2, remove_outliers_norm))

metric.list.NextSeq.scaled <- na.omit(metric.list.NextSeq.outlier)
metric.list.NextSeq.scaled[c(prebam,postbam)] <- as.data.frame(apply(metric.list.NextSeq.scaled[c(prebam,postbam)], 2, function(x) {
  rescale(x, to=c(-1,1))
}))


metric.list.NextSeq.scaled$threshold <- factor(metric.list.NextSeq.scaled$threshold, levels = c("High", "Norm", "Low"))
df_melted = melt(metric.list.NextSeq.scaled[-c(2:3)][c(1,3,4,2,5:22)], id.vars = c('UniqueID', 'threshold'), na.rm = TRUE)
df_melted
mean.lines <- ggplot(df_melted, aes(x = variable, y = value, fill = threshold)) +
  geom_boxplot(alpha = 0.5) +
  scale_fill_manual(values=c("red", "green", "blue"), name = "Threshold", labels = c("Above", "Normal", "Below")) +
  ggtitle("Mean scaled metric change", subtitle = "compared to the Prephasing median threshold (NextSeq)") + 
  ylab("Change from center") + 
  theme(axis.text.x=element_text(angle = 90, size = 15),
        plot.title = element_text(size = 20),
        plot.subtitle = element_text(size = 15),
        legend.text = element_text(size = 10),
        axis.text.y = element_text(size = 12),
        axis.title.y = element_text(size = 15 )) 

mean.lines

ggsave(
  "NextSeq_thresholdPrephasing_change.png",
  plot = mean.lines,
  limitsize = TRUE,
  scale = 1,
  width = 14,
  height = 7
)
```

```{r}

res <- perform_t.tests(metric.list.NextSeq[-c(1:3,5,6)], test.low = F)

res[res$Significant == T,]
```
### MiSeq
```{r}

me.prephasing <- (median(metric.list.MiSeq$PrePhasing) + sd(metric.list.MiSeq$PrePhasing) * 2)
metric.list.MiSeq$threshold <- unlist(lapply(metric.list.MiSeq$PrePhasing, function(x, center=me.prephasing) {
  val <- x
  if (val > center) {
    return("High")
  }
  return("Norm")
}))

metric.list.MiSeq.outlier <- metric.list.MiSeq
metric.list.MiSeq.outlier[metric.list.MiSeq$threshold == "High",][c(prebam,postbam)] <- as.data.frame(apply(metric.list.MiSeq[metric.list.MiSeq$threshold == "High",][c(prebam,postbam)], 2, remove_outliers_norm))

metric.list.MiSeq.outlier[metric.list.MiSeq$threshold == "Norm",][c(prebam,postbam)] <- as.data.frame(apply(metric.list.MiSeq[metric.list.MiSeq$threshold == "Norm",][c(prebam,postbam)], 2, remove_outliers_norm))


metric.list.MiSeq.outlier[metric.list.MiSeq$threshold == "Low",][c(prebam,postbam)] <- as.data.frame(apply(metric.list.MiSeq[metric.list.MiSeq$threshold == "Low",][c(prebam,postbam)], 2, remove_outliers_norm))

metric.list.MiSeq.scaled <- na.omit(metric.list.MiSeq.outlier)
metric.list.MiSeq.scaled[c(prebam,postbam)] <- as.data.frame(apply(metric.list.MiSeq.scaled[c(prebam,postbam)], 2, function(x) {
  rescale(x, to=c(-1,1))
}))


metric.list.MiSeq.scaled$threshold <- factor(metric.list.MiSeq.scaled$threshold, levels = c("High", "Norm", "Low"))
df_melted = melt(metric.list.MiSeq.scaled[-c(2:3)][c(1,3,4,2,5:22)], id.vars = c('UniqueID', 'threshold'), na.rm = TRUE)
df_melted
mean.lines <- ggplot(df_melted, aes(x = variable, y = value, fill = threshold)) +
  geom_boxplot(alpha = 0.5) +
  scale_fill_manual(values=c("red", "green", "blue"), name = "Threshold", labels = c("Above", "Normal", "Below")) +
  ggtitle("Mean scaled metric change", subtitle = "compared to the Prephasing median threshold (MiSeq)") + 
  ylab("Change from center") + 
  theme(axis.text.x=element_text(angle = 90, size = 15),
        plot.title = element_text(size = 20),
        plot.subtitle = element_text(size = 15),
        legend.text = element_text(size = 10),
        axis.text.y = element_text(size = 12),
        axis.title.y = element_text(size = 15 )) 

mean.lines

ggsave(
  "MiSeq_thresholdPrephasing_change.png",
  plot = mean.lines,
  limitsize = TRUE,
  scale = 1,
  width = 14,
  height = 7
)
```

```{r}

res <- perform_t.tests(metric.list.MiSeq[-c(1:3,5,6)], test.low = F)

res[res$Significant == T,]
```
## Phasing

### NextSeq
```{r}

me.phasing <- (median(metric.list.NextSeq$Phasing) + sd(metric.list.NextSeq$Phasing) * 2)
metric.list.NextSeq$threshold <- unlist(lapply(metric.list.NextSeq$Phasing, function(x, center=me.phasing) {
  val <- x
  if (val > center) {
    return("High")
  }
  return("Norm")
}))

metric.list.NextSeq.outlier <- metric.list.NextSeq
metric.list.NextSeq.outlier[metric.list.NextSeq$threshold == "High",][c(prebam,postbam)]
metric.list.NextSeq.outlier[metric.list.NextSeq$threshold == "High",][c(prebam,postbam)] <- as.data.frame(apply(metric.list.NextSeq[metric.list.NextSeq$threshold == "High",][c(prebam,postbam)], 2, remove_outliers_norm))

metric.list.NextSeq.outlier[metric.list.NextSeq$threshold == "Norm",][c(prebam,postbam)] <- as.data.frame(apply(metric.list.NextSeq[metric.list.NextSeq$threshold == "Norm",][c(prebam,postbam)], 2, remove_outliers_norm))


metric.list.NextSeq.scaled <- na.omit(metric.list.NextSeq.outlier)

metric.list.NextSeq.scaled[c(prebam, postbam)] <- as.data.frame(apply(metric.list.NextSeq.scaled[c(prebam, postbam)], 2, function(x) {
  rescale(x, to=c(-1,1))
}))

metric.list.NextSeq.scaled[metric.list.NextSeq.scaled$threshold == "Norm",]
metric.list.NextSeq.scaled$threshold <- factor(metric.list.NextSeq.scaled$threshold, levels = c("High", "Norm", "Low"))
df_melted = melt(metric.list.NextSeq.scaled[c(1,6,5,4,7:24)], id.vars = c('UniqueID', 'threshold'), na.rm = TRUE)
df_melted
mean.lines <- ggplot(df_melted, aes(x = variable, y = value, fill = threshold)) +
  geom_boxplot(alpha = 0.5) +
  scale_fill_manual(values=c("red", "green", "blue"), name = "Threshold", labels = c("Above", "Normal", "Below")) +
  ggtitle("Mean scaled metric change", subtitle = "compared to the Phasing higher threshold (NextSeq)") + 
  ylab("Change from center") + 
  theme(axis.text.x=element_text(angle = 90, size = 15),
        plot.title = element_text(size = 20),
        plot.subtitle = element_text(size = 15),
        legend.text = element_text(size = 10),
        axis.text.y = element_text(size = 12),
        axis.title.y = element_text(size = 15 )) 

mean.lines

ggsave(
  "NextSeq_thresholdPhasing_change.png",
  plot = mean.lines,
  limitsize = TRUE,
  scale = 1,
  width = 14,
  height = 7
)
```

```{r}

res <- perform_t.tests(metric.list.NextSeq[-c(1:3, 5,6)], test.low = F)

res[res$Significant == T,]
```

### MiSeq
```{r}

me.phasing <- median(metric.list.MiSeq$Phasing)
metric.list.MiSeq$threshold <- unlist(lapply(metric.list.MiSeq$Phasing, function(x, center=me.phasing) {
  val <- x
  if (val > center) {
    return("High")
  }
  return("Norm")
}))

metric.list.MiSeq.outlier <- metric.list.MiSeq
metric.list.MiSeq.outlier[metric.list.MiSeq$threshold == "High",][c(prebam,postbam)]
metric.list.MiSeq.outlier[metric.list.MiSeq$threshold == "High",][c(prebam,postbam)] <- as.data.frame(apply(metric.list.MiSeq[metric.list.MiSeq$threshold == "High",][c(prebam,postbam)], 2, remove_outliers_norm))

metric.list.MiSeq.outlier[metric.list.MiSeq$threshold == "Norm",][c(prebam,postbam)] <- as.data.frame(apply(metric.list.MiSeq[metric.list.MiSeq$threshold == "Norm",][c(prebam,postbam)], 2, remove_outliers_norm))


metric.list.MiSeq.scaled <- na.omit(metric.list.MiSeq.outlier)

metric.list.MiSeq.scaled[c(prebam, postbam)] <- as.data.frame(apply(metric.list.MiSeq.scaled[c(prebam, postbam)], 2, function(x) {
  rescale(x, to=c(-1,1))
}))

metric.list.MiSeq.scaled[metric.list.MiSeq.scaled$threshold == "Norm",]
metric.list.MiSeq.scaled$threshold <- factor(metric.list.MiSeq.scaled$threshold, levels = c("High", "Norm", "Low"))
df_melted = melt(metric.list.MiSeq.scaled[c(1,6,5,7:24)], id.vars = c('UniqueID', 'threshold'), na.rm = TRUE)
df_melted
mean.lines <- ggplot(df_melted, aes(x = variable, y = value, fill = threshold)) +
  geom_boxplot(alpha = 0.5) +
  scale_fill_manual(values=c("red", "green", "blue"), name = "Threshold", labels = c("Above", "Normal", "Below")) +
  ggtitle("Mean scaled metric change", subtitle = "compared to the Phasing higher threshold (MiSeq)") + 
  ylab("Change from center") + 
  theme(axis.text.x=element_text(angle = 90, size = 15),
        plot.title = element_text(size = 20),
        plot.subtitle = element_text(size = 15),
        legend.text = element_text(size = 10),
        axis.text.y = element_text(size = 12),
        axis.title.y = element_text(size = 15 )) 

mean.lines

ggsave(
  "MiSeq_thresholdPhasing_change.png",
  plot = mean.lines,
  limitsize = TRUE,
  scale = 1,
  width = 14,
  height = 7
)
```

```{r}

res <- perform_t.tests(metric.list.MiSeq[-c(1:3, 5,6)], test.low = F)

res
```

## Cluster Denisty
##Next Seq

```{r}
metric.list.NextSeq$threshold <- unlist(lapply(metric.list.NextSeq$ClusterDensity, function(x) {
  val <- x
  if (val > 220) {
    return("High")
  }
  if (val < 170) {
    return("Low")
  }
  return("Norm")
}))

metric.list.NextSeq.outlier <- metric.list.NextSeq
metric.list.NextSeq.outlier[metric.list.NextSeq$threshold == "High",][c(prebam,postbam)] <- as.data.frame(apply(metric.list.NextSeq[metric.list.NextSeq$threshold == "High",][c(prebam,postbam)], 2, remove_outliers_norm))

metric.list.NextSeq.outlier[metric.list.NextSeq$threshold == "Norm",][c(prebam,postbam)] <- as.data.frame(apply(metric.list.NextSeq[metric.list.NextSeq$threshold == "Norm",][c(prebam,postbam)], 2, remove_outliers_norm))


metric.list.NextSeq.outlier[metric.list.NextSeq$threshold == "Low",][c(prebam,postbam)] <- as.data.frame(apply(metric.list.NextSeq[metric.list.NextSeq$threshold == "Low",][c(prebam,postbam)], 2, remove_outliers_norm))

metric.list.NextSeq.scaled <- na.omit(metric.list.NextSeq.outlier)
metric.list.NextSeq.scaled[c(prebam,postbam)] <- as.data.frame(apply(metric.list.NextSeq.scaled[c(prebam,postbam)], 2, function(x) {
  rescale(x, to=c(-1,1))
}))


metric.list.NextSeq.scaled$threshold <- factor(metric.list.NextSeq.scaled$threshold, levels = c("High", "Norm", "Low"))
df_melted = melt(metric.list.NextSeq.scaled[c(1,7,5,6,4, 8:24)], id.vars = c('UniqueID', 'threshold'), na.rm = TRUE)
df_melted
mean.lines <- ggplot(df_melted, aes(x = variable, y = value, fill = threshold)) +
  geom_boxplot(alpha = 0.5) +
  scale_fill_manual(values=c("red", "green", "blue"), name = "Threshold", labels = c("Above", "Between", "Below")) +
  ggtitle("Mean scaled metric change", subtitle = "compared to the Cluster density thresholds 170-220 K/mm2") + 
  ylab("Change from center") + 
  theme(axis.text.x=element_text(angle = 90, size = 15),
        plot.title = element_text(size = 20),
        plot.subtitle = element_text(size = 15),
        legend.text = element_text(size = 10),
        axis.text.y = element_text(size = 12),
        axis.title.y = element_text(size = 15 )) 

mean.lines

ggsave(
  "NextSeq_thresholdClusterDensity_change.png",
  plot = mean.lines,
  limitsize = TRUE,
  scale = 1,
  width = 14,
  height = 7
)
```
```{r}

res <- perform_t.tests(metric.list.NextSeq[-c(1:3, 7)])

res[[1]][res[[1]]$Significant == T,]
res[[2]][res[[2]]$Significant == T,]
```

### MiSeq

```{r}
metric.list.MiSeq$threshold <- unlist(lapply(metric.list.MiSeq$ClusterDensity, function(x) {
  val <- x
  if (val > 1200) {
    return("High")
  }
  if (val < 1000) {
    return("Low")
  }
  return("Norm")
}))

metric.list.MiSeq.outlier <- metric.list.MiSeq
metric.list.MiSeq.outlier[metric.list.MiSeq$threshold == "High",][c(prebam,postbam)] <- as.data.frame(apply(metric.list.MiSeq[metric.list.MiSeq$threshold == "High",][c(prebam,postbam)], 2, remove_outliers_norm))

metric.list.MiSeq.outlier[metric.list.MiSeq$threshold == "Norm",][c(prebam,postbam)] <- as.data.frame(apply(metric.list.MiSeq[metric.list.MiSeq$threshold == "Norm",][c(prebam,postbam)], 2, remove_outliers_norm))


metric.list.MiSeq.outlier[metric.list.MiSeq$threshold == "Low",][c(prebam,postbam)] <- as.data.frame(apply(metric.list.MiSeq[metric.list.MiSeq$threshold == "Low",][c(prebam,postbam)], 2, remove_outliers_norm))

metric.list.MiSeq.scaled <- na.omit(metric.list.MiSeq.outlier)
metric.list.MiSeq.scaled[c(prebam,postbam)] <- as.data.frame(apply(metric.list.MiSeq.scaled[c(prebam,postbam)], 2, function(x) {
  rescale(x, to=c(-1,1))
}))


metric.list.MiSeq.scaled$threshold <- factor(metric.list.MiSeq.scaled$threshold, levels = c("High", "Norm", "Low"))
df_melted = melt(metric.list.MiSeq.scaled[c(1,7,5,6,4, 8:24)], id.vars = c('UniqueID', 'threshold'), na.rm = TRUE)
df_melted
mean.lines <- ggplot(df_melted, aes(x = variable, y = value, fill = threshold)) +
  geom_boxplot(alpha = 0.5) +
  scale_fill_manual(values=c("red", "green", "blue"), name = "Threshold", labels = c("Above", "Between", "Below")) +
  ggtitle("Mean scaled metric change", subtitle = "compared to the Cluster density thresholds 170-220 K/mm2") + 
  ylab("Change from center") + 
  theme(axis.text.x=element_text(angle = 90, size = 15),
        plot.title = element_text(size = 20),
        plot.subtitle = element_text(size = 15),
        legend.text = element_text(size = 10),
        axis.text.y = element_text(size = 12),
        axis.title.y = element_text(size = 15 )) 

mean.lines

ggsave(
  "MiSeq_thresholdClusterDensity_change.png",
  plot = mean.lines,
  limitsize = TRUE,
  scale = 1,
  width = 14,
  height = 7
)
```
## Q30
### NextSeq
```{r}

medi <- (mean(metric.list.NextSeq$Average_Q30) - sd(metric.list.NextSeq$Average_Q30) * 2 )

metric.list.NextSeq$threshold <- unlist(lapply(metric.list.NextSeq$Average_Q30, function(x, med=medi) {
  val <- x
  if (val < med) {
    return("Low")
  }
  return("Norm")
}))

metric.list.NextSeq.outlier <- metric.list.NextSeq
metric.list.NextSeq.outlier[metric.list.NextSeq$threshold == "High",][c(prebam, postbam)] <- as.data.frame(apply(metric.list.NextSeq[metric.list.NextSeq$threshold == "High",][c(prebam, postbam)], 2, remove_outliers_norm))

metric.list.NextSeq.outlier
metric.list.NextSeq.outlier[metric.list.NextSeq$threshold == "Norm",][c(prebam, postbam)] <- as.data.frame(apply(metric.list.NextSeq[metric.list.NextSeq$threshold == "Norm",][c(prebam, postbam)], 2, remove_outliers_norm))


metric.list.NextSeq.outlier[metric.list.NextSeq$threshold == "Low",][c(prebam, postbam)] <- as.data.frame(apply(metric.list.NextSeq[metric.list.NextSeq$threshold == "Low",][c(prebam, postbam)], 2, remove_outliers_norm))

metric.list.NextSeq.scaled <- na.omit(metric.list.NextSeq.outlier)
metric.list.NextSeq.scaled[c(prebam, postbam)] <- as.data.frame(apply(metric.list.NextSeq.scaled[c(prebam, postbam)], 2, function(x) {
  rescale(x, to=c(-1,1))
}))


metric.list.NextSeq.scaled$threshold <- factor(metric.list.NextSeq.scaled$threshold, levels = c("Norm", "Low"))
df_melted = melt(metric.list.NextSeq.scaled[-c(2)][c(1,7,3,4,5,6,8:23)], id.vars = c('UniqueID', 'threshold'), na.rm = TRUE)
df_melted
mean.lines <- ggplot(df_melted, aes(x = variable, y = value, fill = threshold)) +
  geom_boxplot(alpha = 0.5) +
  scale_fill_manual(values=c("green", "blue"), name = "Threshold", labels = c("Normal", "Below")) +
  ggtitle("Mean scaled metric change", subtitle = "compared to the Q30 threshold set as sd(Q30) * 2") + 
  ylab("Change from center") + 
  theme(axis.text.x=element_text(angle = 90, size = 15),
        plot.title = element_text(size = 20),
        plot.subtitle = element_text(size = 15),
        legend.text = element_text(size = 10),
        axis.text.y = element_text(size = 12),
        axis.title.y = element_text(size = 15 )) 

mean.lines

ggsave(
  "NextSeq_thresholdQ30_change.png",
  plot = mean.lines,
  limitsize = TRUE,
  scale = 1,
  width = 14,
  height = 7
)
```

```{r}

res <- perform_t.tests(metric.list.NextSeq[-c(1:3,8)], test.high = F)

res[res$Significant == T,]
```

```{r}

medi <- (mean(metric.list.MiSeq$Average_Q30) - sd(metric.list.MiSeq$Average_Q30) * 2 )

metric.list.MiSeq$threshold <- unlist(lapply(metric.list.MiSeq$Average_Q30, function(x, med=medi) {
  val <- x
  if (val < med) {
    return("Low")
  }
  return("Norm")
}))

metric.list.MiSeq.outlier <- metric.list.MiSeq
metric.list.MiSeq.outlier[metric.list.MiSeq$threshold == "High",][c(prebam, postbam)] <- as.data.frame(apply(metric.list.MiSeq[metric.list.MiSeq$threshold == "High",][c(prebam, postbam)], 2, remove_outliers_norm))

metric.list.MiSeq.outlier
metric.list.MiSeq.outlier[metric.list.MiSeq$threshold == "Norm",][c(prebam, postbam)] <- as.data.frame(apply(metric.list.MiSeq[metric.list.MiSeq$threshold == "Norm",][c(prebam, postbam)], 2, remove_outliers_norm))


metric.list.MiSeq.outlier[metric.list.MiSeq$threshold == "Low",][c(prebam, postbam)] <- as.data.frame(apply(metric.list.MiSeq[metric.list.MiSeq$threshold == "Low",][c(prebam, postbam)], 2, remove_outliers_norm))

metric.list.MiSeq.scaled <- na.omit(metric.list.MiSeq.outlier)
metric.list.MiSeq.scaled[c(prebam, postbam)] <- as.data.frame(apply(metric.list.MiSeq.scaled[c(prebam, postbam)], 2, function(x) {
  rescale(x, to=c(-1,1))
}))


metric.list.MiSeq.scaled$threshold <- factor(metric.list.MiSeq.scaled$threshold, levels = c("Norm", "Low"))
df_melted = melt(metric.list.MiSeq.scaled[-c(2)][c(1,7,3,4,5,6,8:23)], id.vars = c('UniqueID', 'threshold'), na.rm = TRUE)
df_melted
mean.lines <- ggplot(df_melted, aes(x = variable, y = value, fill = threshold)) +
  geom_boxplot(alpha = 0.5) +
  scale_fill_manual(values=c("green", "blue"), name = "Threshold", labels = c("Normal", "Below")) +
  ggtitle("Mean scaled metric change", subtitle = "compared to the Q30 threshold set as sd(Q30) * 2") + 
  ylab("Change from center") + 
  theme(axis.text.x=element_text(angle = 90, size = 15),
        plot.title = element_text(size = 20),
        plot.subtitle = element_text(size = 15),
        legend.text = element_text(size = 10),
        axis.text.y = element_text(size = 12),
        axis.title.y = element_text(size = 15 )) 

mean.lines

ggsave(
  "MiSeq_thresholdQ30_change.png",
  plot = mean.lines,
  limitsize = TRUE,
  scale = 1,
  width = 14,
  height = 7
)
```
```{r}

res <- perform_t.tests(metric.list.MiSeq[-c(1:3,8)], test.high = F)

res[res$Significant == T,]
```
