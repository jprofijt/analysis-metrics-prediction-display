---
title: "AnalysisLog"
author: "Jouke Profijt"
date: "6/2/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = '/Users/jouke/Projects/Analysis metrics/' )
```

# 1. Data preparation
```{r echo=FALSE}
library(stringr)
library(dplyr)


# Retrieve DNA isolation and sample preparation data from supplied csv:
prepData <- read.csv2("data/GokuVsVegeta/QXTData.csv", sep = "\t", header = F, dec = ",")
colnames(prepData) <- c("SampleName", "Concentration", "A260_280", "A260_230", "ProcessStepId", "ExitDate", "ContainerPosition", "RequestId", "BatchId", "FinishedBy", "isFirstPriority", "FieldName", "DataType", "Value")

prepData.pur <- prepData %>% select(SampleName, A260_230, A260_280)

prepData.pur <- distinct(prepData.pur)

# format DNA number
prepData.pur$SampleName <- apply(prepData.pur, 1, function(x) {
  str_remove(x[1], "-")
})

prepData.pur$A260_230 <- apply(prepData.pur, 1, function(x) {
  as.numeric(sub(",", ".", x[2], fixed = TRUE))
})

prepData.pur$A260_280 <- apply(prepData.pur, 1, function(x) {
  as.numeric(sub(",", ".", x[3], fixed = TRUE))
})
head(prepData.pur)
```

```{r}
library(DBI)
library(stringr)
# Retrieve parsed sample sheets from database file
connection = dbConnect(RSQLite::SQLite(), "data/SQLITE/databaseFull.db")
samples <- dbReadTable(connection, "Samples")
dbDisconnect(connection)
samples$DNA_numbers <- as.factor(apply(samples, 1, function(x) {
  ids <- unlist(strsplit(x[1], "_"))
  ids[3]
}))

# Parse Sample capturing kit design number from sample ID
samples$DesignNumber <- as.factor(apply(samples, 1, function(x) {
  ids <- unlist(strsplit(x[1], "_"))
  DN <- ids[6]
  if (is.null(DN) | is.na(DN)) {
    return(x["capturingKit"])
  } else {
    return(DN)
  }
  }))

# only retrieve samples with a correct DNA identifier
samples <- subset(samples, ((grepl("DNA\\d+", DNA_numbers) )))


instruments <- function(row) {
  # function to parse sequencer machine used for the sample using the sequencer id
  x <- row["Sequencer"]
  flowcell <- row["Flowcell"]
  if (str_detect(x, regex("HWI-M[0-9]{4}$"))) {
   return("MiSeq")
 }
  if (str_detect(x, regex("HWUSI"))) {
   return("Genome Analyzer IIx")
  }
  if (str_detect(x, regex("M[0-9]{5}$"))) {
   return("MiSeq")
  }
  if (str_detect(x, regex("HWI-C[0-9]{5}$"))) {
   return("HiSeq 1500")
  }
  if (str_detect(x, regex("C[0-9]{5}$"))) {
   return("HiSeq 1500")
  }
  if (str_detect(x, regex("HWI-D[0-9]{5}$"))) {
   return("HiSeq 2500")
  }
  if (str_detect(x, regex("D[0-9]{5}$"))) {
   return("HiSeq 2500")
  }
  if (str_detect(x, regex("J[0-9]{5}$"))) {
   return("HiSeq 3000")
  }
  if (str_detect(x, regex("K[0-9]{5}$"))) {
    return(check_flowcell(row))
  }
  if (str_detect(x, regex("E[0-9]{5}$"))) {
   return("HiSeq X")
  }
  if (str_detect(x, regex("NB[0-9]{6}$"))) {
   return("NextSeq")
  }
  if (str_detect(x, regex("NS[0-9]{6}$"))) {
   return("NextSeq")
  }
  if (str_detect(x, regex("MN[0-9]{5}$"))) {
   return("MiniSeq")
  }
  return(check_flowcell(row))
}

check_flowcell <- function(row) {
  # secondary function to parse sequencer machine used for the sample using the flowcell id
  x <- row["flowcell"]
  if (str_detect(x, regex("C[A-Z,0-9]{4}ANXX$"))) { return("HiSeq 1500")}
  if (str_detect(x, regex("C[A-Z,0-9]{4}ACXX$"))) { return("HiSeq 1000")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}ADXX$"))) { return("HiSeq 1500")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BCXX$"))) { return("HiSeq 1500")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BCXY$"))) { return("HiSeq 1500")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BBXX$"))) { return("HiSeq 4000")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BBXY$"))) { return("HiSeq 4000")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}CCXX$"))) { return("HiSeq X")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}CCXY$"))) { return("HiSeq X")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}ALXX$"))) { return("HiSeq X")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BGXX$"))) { return("NextSeq")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BGXY$"))) { return("NextSeq")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}BGX2$"))) { return("NextSeq")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}AFXX$"))) { return("NextSeq")}
  if (str_detect(x, regex("A[A-Z,0-9]{4}$"))) { return("MiSeq")}
  if (str_detect(x, regex("B[A-Z,0-9]{4}$"))) { return("MiSeq")}
  if (str_detect(x, regex("D[A-Z,0-9]{4}$"))) { return("MiSeq")}
  if (str_detect(x, regex("G[A-Z,0-9]{4}$"))) { return("MiSeq")}
  if (str_detect(x, regex("H[A-Z,0-9]{4}DMXX$"))) { return("NovaSeq")}
  return(row["Sequencer"]) # if no instrument type can be found, return the sequencer id to keep it destinguiasable

}

# format sample sheet information
samples$Instrument <- apply(samples, 1, instruments)
samples$startDate <- as.Date(samples$startDate)
samples <- samples[order(samples$startDate),]


# group sample into Not reinserted or Reinserted when they have been reused as identiefied by the DNA_number
l <- list()
v <- c()
i <- 1
for (DNA_number in samples$DNA_numbers) {
  unique_combo <- paste0(DNA_number, samples$DesignNumber[i])
  if (is.null(l[unique_combo][[1]])) {
    l[unique_combo] <- i
    v <- append(v, "Not Reinserted")
  } else {
    v[l[unique_combo][[1]]] <- "Reinserted"
    v <- append(v, "Not Reinserted")
    l[unique_combo] <- i
  }
  i <- i + 1
}
samples$Used <- as.factor(v)
rm(v, l)
head(samples)
```

```{r}
library(dplyr)
# Retrieve Post-bam and Sequencing information from database
## Sequencing: Runs, RunSummary & CD
## Post-Bam: ASM, hs, InsertSizes, FL
connection = dbConnect(RSQLite::SQLite(), "data/SQLITE/databaseFull.db")
ASM <- dbReadTable(connection, "AlignmentSummaryMetrics")
ASM <- ASM[ASM$Category == "PAIR",]
hs <- dbReadTable(connection, "hsMetrics")
InsertSizes <- dbReadTable(connection, "InsertSizes")
RUNS <- dbReadTable(connection, "RUNS")
RunSummary <- dbReadTable(connection, "RunSummary")
res <- dbSendQuery(connection, "
                  SELECT
                  Samples.ID as SampleID,
                  avg(Lanes.DensityMAX) as ClusterDensity,
                  avg(Lanes.Q30) as Average_Q30,
                  avg(Lanes.LegacyPhasing) as Phasing,
                  avg(Lanes.LegacyPrePhasing) as PrePhasing,
                  avg(Lanes.ClusterMAX) as ClusterPF
                  FROM Samples 
                  INNER JOIN RUNS ON Samples.Sequencer==RUNS.Sequencer AND Samples.Run==RUNS.Number AND Samples.startDate==RUNS.Date 
                  INNER JOIN RunSummary ON RUNS.UniqueID==RunSummary.UniqueID
                  INNER JOIN Lanes ON RUNS.UniqueID==Lanes.UniqueID
                  GROUP BY Samples.ID
                  ORDER BY RUNS.Date")
CD <- dbFetch(res)
FL <- dbReadTable(connection, "FlagstatMetrics")
dbDisconnect(connection)
RunSummary <- aggregate(RunSummary[, c(2:4, 6:7)], list(RunSummary$UniqueID), sum)

# combine data into one
RunMetrics <- left_join(RUNS, RunSummary, by = c("UniqueID" = "Group.1"))
RunMetrics$Date <- as.Date(RunMetrics$Date)
data <- left_join(RunMetrics, samples, by = c("Sequencer"= "Sequencer", "Number" = "run", "Date" = "startDate"))

data <- left_join(prepData.pur, data, by = c("SampleName" = "DNA_numbers") )
data <- left_join(data, CD, by = c("ID" = "SampleID"))
data <- left_join(data, ASM, by = c("ID" = "SampleID"))
data <- left_join(data, hs, by = c("ID" = "SampleID", "RunID.y" = "RunID"))
data <- left_join(data, InsertSizes, by = c("ID" = "SampleID", "RunID.y" = "RunID"))
data <- left_join(data, FL, by = c("ID" = "SampleID", "RunID.y" = "RunID"))

data$Used <- as.factor(data$Used)
data$Instrument <- as.factor(data$Instrument)
dbDisconnect(connection)
rm(ASM,hs,InsertSizes,FL,CD,RunMetrics, RUNS, RunSummary, res, connection, DNA_number, i, unique_combo, v, check_flowcell, instruments)

# omit na values
data2 <- na.omit(data)

complete.data <- data.frame(data2[c(1,4:9,15:21, 27,28,47,103)], apply(data2[c(2,3,10:14,22:26, 29:46, 48:102, 104:142)], 2, as.numeric))

variance.data <- apply(complete.data[19:142], 2, var)

# Remove nummeric columns with 0 varance, as they do not provide any usable information
complete.data.var <- complete.data %>% select(c(names(complete.data[1:18]), names(variance.data[variance.data != 0])))
head(complete.data.var)
```


```{r echo=FALSE}
length(complete.data.var$Yield) == sum(complete.data.var$Yield == complete.data.var$ProjectedYield)
```
Yield and Projected yield are the same in our instance so Projected yield will be removed from the data

```{r}
length(complete.data.var$TotalReads.x) == sum(complete.data.var$TotalReads.x == complete.data.var$TotalReads.y)
```
Total reads is duplicated so we remove 1 of the two columns.

```{r}
length(complete.data.var$TotalReads.x) == sum(complete.data.var$TotalReads.x == complete.data.var$PFreads.x)
```
```{r}
length(complete.data.var$TotalReads.x) == sum(complete.data.var$TotalReads.y == complete.data.var$PFreads.y)
```
The number of reads passing filter is always equal to The total reads, and is also duplicated

```{r}
length(complete.data.var$TotalReads.x) == sum(complete.data.var$Read1Pass == complete.data.var$Read2Pass)
```
Duplicated Read 1 & read 2 always have the same pass count for the flagstat metrics


lastly Q30 is a percentage and should not exceed 100%, we can use average Q30 per lane instead.

```{r}
complete.data.edit <- complete.data.var %>% select(!c(ProjectedYield, Q30, Read2Pass, TotalReads.y, PFreads.x, PFreads.y, BaitSet, Category, PairOrientation)) # bait set has 1 level, as do Category and PairOrientation
```


```{r}
str(complete.data.edit)
```

This leaves us with a dataset of 6960 samples, with 106 variables.

# 2. Correlation analysis

## Preparation metrics vs Sequencing Metrics

```{r}
library(reshape2)
library(ggplot2)
interop <- complete.data.edit %>% select(Yield, Aligned, Intensity, ClusterDensity, Average_Q30, Phasing, PrePhasing, ClusterPF)
puritys <- complete.data.edit %>% select(A260_230, A260_280)

corMat <- round(cor(x=interop, y=puritys, method = "spearman", use = "complete.obs"), 2)



pur.cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ theme(legend.position = "none") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + xlab("Interop Metrics") + ylab("DNA preparation metrics") + ggtitle("Interop vs DNA purities")

pur.cor.heatmap
rm(puritys, corMat, pur.cor.heatmap)
```
Observation:
* There does not seem to be correlations with dna puritys and Sequencing metrics.

# Sequencing metrics(interop) correlation heatmaps to Post-bam Metrics

## Alignment Summary Metrics
```{r}
library(reshape2)
library(Hmisc)

ASM <- complete.data.edit %>% select(TotalReads.x, PFaligned, PFalignedBases, PFHQmedianMismatches, PFmismatchRate, PFHQErrorRate, PFindelRate, MeanReadLenght, ReadsAllignedInPairs, StrandBalance, ChimerasPercentage, AdapterPercentage)


corMat <- round(cor(x=interop, y=ASM, method = "spearman", use = "complete.obs"), 2)


ASM.cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + xlab("Interop Metrics") + ylab("Alignment Summary Metrics") + ggtitle("Interop vs Alignemnt Summary Metrics")

ASM.cor.heatmap
ggsave(
  "Alignment_Summary_Metrics_heatmap.png",
  plot = ASM.cor.heatmap,
  dpi = 300,
  limitsize = TRUE,
)
rm(corMat, ASM.cor.heatmap)
```
Observations:
* Yield impacts many metrics that are related to the amount of reads produced.
* Aligned (The percentage of reads that align to the PhiX genome)
  * positivly impacts the Adapter sequencers percentage
  * positivly impacts the chimeras percentage
  * negativly impacts the Strand balance
* Intensity could have an negative effect on Error Rates/mismatch rates
* Q30
  * could have an negative effect on Error Rates/mismatch rates
  * could have an negative effect on Chimeras percentage and Strand balance
* Phasing
  * Positive impact on Error rate/mismatch rate
* PrePhasing
  * Positive impact on error RAte/mismatch rate
* ClusterPf (Clusters passing filter)
  * Negative impact on Error Rate/Mismatch rate
  
Interesting metrics:
  * Chimeras Percentage: might suggest sample contamination
  * Mismatch/Error rate: changes might suggest lower quality & has many ivluencing metrics
  
```{r}
res2 <- rcorr(as.matrix(data.frame(interop, ASM)), type = "spearman")
# Aligned positivly impacts the Adapter sequencers percentage
res2$P["AdapterPercentage","Aligned"]
res2$r["AdapterPercentage","Aligned"]

```
The Aligned Metric significantly positivly impacts the Adapter sequencers percentage with a p value of 0 and a spearman Correlation coefficent of 0.81

```{r}
res2 <- rcorr(as.matrix(data.frame(interop, ASM)), type = "spearman")
# Aligned positivly impacts the Adapter sequencers percentage
res2$P["ChimerasPercentage","Aligned"]
res2$r["ChimerasPercentage","Aligned"]

```

The Aligned Metric significantly positivly impacts the chimeras percentage with a p value of 0 and a spearman Correlation coefficent of 0.31

```{r}
res2 <- rcorr(as.matrix(data.frame(interop, ASM)), type = "spearman")
# Aligned positivly impacts the Adapter sequencers percentage
res2$P["ChimerasPercentage","Average_Q30"]
res2$r["ChimerasPercentage","Average_Q30"]

```
```{r}
res2 <- rcorr(as.matrix(data.frame(interop, ASM)), type = "spearman")
# Aligned positivly impacts the Adapter sequencers percentage
res2$P["StrandBalance","Aligned"]
res2$r["StrandBalance","Aligned"]
```
The Aligned Metric significantly Negativly impacts the strand balance with a p value of 0 and a spearman Correlation coefficent of 0.31

```{r}
res2$P["StrandBalance","Average_Q30"]
res2$r["StrandBalance","Average_Q30"]
```

```{r}
res2$P["StrandBalance","Phasing"]
res2$r["StrandBalance","Phasing"]
```

```{r}
res2$P["StrandBalance","PrePhasing"]
res2$r["StrandBalance","PrePhasing"]
```
```{r}
res2$P["PFHQErrorRate","Intensity"]
res2$r["PFHQErrorRate","Intensity"]
```
```{r}
res2$P["PFHQErrorRate","Average_Q30"]
res2$r["PFHQErrorRate","Average_Q30"]
```
```{r}
res2$P["PFHQErrorRate","Phasing"]
res2$r["PFHQErrorRate","Phasing"]
```

```{r}
res2$P["PFHQErrorRate","PrePhasing"]
res2$r["PFHQErrorRate","PrePhasing"]
```
```{r}
res2$P["PFHQErrorRate","ClusterPF"]
res2$r["PFHQErrorRate","ClusterPF"]
```
## HS Metrics

```{r}
connection = dbConnect(RSQLite::SQLite(), "data/SQLITE/databaseFull.db")
hsm <- dbListFields(connection, "hsMetrics")
hsm <- hsm[hsm %in% names(complete.data.edit)]
HS <- complete.data.edit %>% select(hsm)
HS
HS1 <- HS[1:10]
corMat <- round(cor(x=HS1, y=interop, method = "spearman", use = "complete.obs"), 2)



hs.cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + xlab("Hs Metrics") + ylab("Interop") + ggtitle("Interop vs hs metrics 1")

hs.cor.heatmap
```
Observations:
* ClusterDensity 
  *Negitavly affects the size of the terretories, which is expected
  *Positivly Affects the MeanBaitCoverage, MeanTargetCoverage, and MedianTargetCoverage
* ClusterPF
  * Negativly affects MeanBaitCoverage and MeanTargetCoverage
  

```{r}
HS2 <- HS[11:20]
corMat <- round(cor(x=HS2, y=interop, method = "spearman", use = "complete.obs"), 2)



hs.cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + xlab("Hs Metrics") + ylab("Interop") + ggtitle("Interop vs hs metrics 2")

hs.cor.heatmap
```
Observations:
* ClusterDensity
  * Negitivly affects the ExcBaseQPct(fraction of aligned bases that were filtered out becouse of low quality)
  * positivly affects the TargetBases with 1X & 2X or greater coverage
* Aligned
  * Negativly affects the ExcDupePCT, or the fraction of aligned bases taht were filtered out because they were in reads marked as duplicate
  * Positivly affects the ExcMapQPct, or the fraction of aligned bases that were filtered out because they were in reads with low mapping quality
```{r}
HS3 <- HS[21:30]
corMat <- round(cor(x=HS3, y=interop, method = "spearman", use = "complete.obs"), 2)



hs.cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + xlab("Hs Metrics") + ylab("Interop") + ggtitle("Interop vs hs metrics 3")

hs.cor.heatmap
```
Observations:
The target coverage metrics seem to vary in the same way, as do the hsPenalty metrics (hybrid selection penalty)
```{r}
HS4 <- HS[31:35]
corMat <- round(cor(x=HS4, y=interop, method = "spearman", use = "complete.obs"), 2)



hs.cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + xlab("Hs Metrics") + ylab("Interop") + ggtitle("Interop vs hs metrics 4")

hs.cor.heatmap
```

Observations:
The ClusterDensity seems to affect the sesnitifty to detect Hetrozygous SNPs and the Hetrozygous SNP sensitifity scaled to th e Qscore in a positive way.

## Insert Size metrics

```{r}
connection = dbConnect(RSQLite::SQLite(), "data/SQLITE/databaseFull.db")
ISM <- dbListFields(connection, "InsertSizes")
ISM <- ISM[ISM %in% names(complete.data.edit)]
IS <- complete.data.edit %>% select(ISM)
corMat <- round(cor(x=interop, y=IS, method = "spearman", use = "complete.obs"), 2)



IS.cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + xlab("Interop Metrics") + ylab("Insert Size Metrics") + theme(legend.position = "none") + ggtitle("Interop vs InsertSize metrics")

IS.cor.heatmap
```
Observations:
* MedianSize which is the representative Insert size metric for a sample:
  * might be negativly affected by the aligned metric
  No big influencers it seems.
  
## FLagstat Metrics

```{r}
connection = dbConnect(RSQLite::SQLite(), "data/SQLITE/databaseFull.db")
FLM <- dbListFields(connection, "FlagstatMetrics")
FLM <- FLM[FLM %in% names(complete.data.edit)]
FL <- complete.data.edit %>% select(FLM)

corMat <- round(cor(x=FL, y=interop, method = "spearman", use = "complete.obs"), 2)



fl.cor.heatmap <- ggplot(data = melt(corMat, na.rm = T), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(colour = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") + 
  theme_minimal()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) + xlab("FlagStat metrics") + ylab("Interop") + ggtitle("Correlations between Interop vs hs metrics")

fl.cor.heatmap
```
Observations:
* Q30 & ClusterPF seem to have a large positive impact on the percentage of mapped reads, And the Singletons percentage, which are rare variants of genetic variation
* Phasing & Prephasing seem to negativly impact the mapped percentage

# 3. Modeling using Gradient Boosting

```{r}
library(tidyverse)
library(caret)
library(xgboost)
# Removal of identification data and metrics with similar correlations
model.data <- complete.data.edit %>% select(-c(SampleName, UniqueID, RunID.x, Number, Flowcell, Sequencer, Date, ID, flowcell, project, capturingKit, RunID.y, W10, W20, W30, W40, W50, W60, W70, W80, W90, W99, TargetBasesPct10X, TargetBasesPct100X, TargetBasesPct1X, TargetBasesPct2X, TargetBasesPct30X, TargetBasesPct40X, TargetBasesPct50X, PFHQErrorRate, TotalPass, SecondaryPass, DuplicatePass, MappedPass, PairedSeqPass, Read1Pass, PoperPairPass, SelfAndMatePass, SingletonsPass, MateOnDiffChromosomeLowPass, MateOnDiffChromosomeHighPass, MaxSize, MedianAbsoluteDeviation, HsPenalty100X, HsPenalty10X, HsPenalty30X, HsPenalty40X, HsPenalty50X))

training.data <- model.data$Used %>% 
  createDataPartition(p = 0.8, list = FALSE)
set.seed(123)
train.data  <- model.data[training.data, ]
test.data <- model.data[-training.data, ]
```

```{r}
# Fit the model on the training set
set.seed(123)
model <- train(
  Used ~., data = train.data, method = "xgbTree",
  trControl = trainControl("cv", number = 10)
  )
# Best tuning parameter
save(model, file = "model.RData")
model$bestTune
```

```{r}
load("model.RData")
predicted.classes <- model %>% predict(test.data)

mean(predicted.classes == test.data$Used)
test.data$predicted <- predicted.classes

table(test.data$Used, test.data$predicted)
```
```{r}
library(ROCR)
a<- as.numeric(test.data$predicted)

b<- as.numeric(test.data$Used)

pred <- prediction(a, b)
auc.tmp <- performance(pred,"auc")
auc <- as.numeric(auc.tmp@y.values)
auc
```
Even Though the area under the curve for the model, is not very accurate, We can sample a list of metrics which might affect the 
```{r}
varImp(model)
```
Because we expect that the A260_280 and The target coverage are indeed important metrics we want to look further into these other defining metrics.

# 4. Testing the data differentces

```{r}
range02 <- function(x){ (x - min(x))/(max(x)-min(x)) * (1 - -1) + -1 }

complete.data.edit$FractionDuplicates <- (1 - complete.data.edit$PFuniqueReads/complete.data.edit$TotalReads.x)
metric.list <- complete.data.edit %>% select(UniqueID,A260_280, A260_230, Intensity, PrePhasing, Phasing, ClusterDensity, TargetBasesPct20X, OnBaitVSselected, PFmismatchRate, ExcMapQPct, MedianTargetCoverage, HetSNPsensitivity, StrandBalance, StandardDeviation, ChimerasPercentage, PFUQaligned, MeanSize, FractionDuplicates, Instrument)

metric.list[metric.list$Instrument == "NB500917R",]$Instrument <- "NextSeq"

metric.list$Instrument <- droplevels(metric.list$Instrument)

metric.list.NextSeq <- metric.list[metric.list$Instrument == "NextSeq",]
metric.list.MiSeq <- metric.list[metric.list$Instrument == "NextSeq",]

metric.list.NextSeq <- metric.list.NextSeq %>% select(!Instrument)
metric.list.MiSeq <- metric.list.MiSeq%>% select(!Instrument)
```

A260_280 threshold:
< 1.8 = low
1.8-2.0 = normal
> 2.0 = high

A260_230 threshold:
< 2.0 = low
2.0 - 2.2 = normal
> 2.2 = high

## Next seq machines
```{r}
metric.list.NextSeq.scaled <- as.data.frame(apply(metric.list.NextSeq, 2, range02))

metric.list.NextSeq$threshold <- unlist(lapply(metric.list.NextSeq$A260_280, function(x) {
  val <- x
  if (val > 2.0) {
    return("High")
  }
  if (val < 1.8) {
    return("Low")
  }
  return("Norm")
}))

metric.list.NextSeq.scaled$threshold <- unlist(lapply(metric.list.NextSeq$A260_280, function(x) {
  val <- x
  if (val > 2.0) {
    return("High")
  }
  if (val < 1.8) {
    return("Low")
  }
  return("Norm")
}))

metric.list.NextSeq.scaled$UniqueID <- metric.list.NextSeq$UniqueID
high.scaled <- metric.list.NextSeq.scaled[metric.list.NextSeq.scaled$threshold == "High",]


a <- as.vector(apply(high.scaled[-c(1,20)], 2, mean))



high.scaled[nrow(high.scaled) + 1,][-c(1,20)] <- a
high.scaled[nrow(high.scaled),][,1] <- 9999
high.scaled[nrow(high.scaled),][,20] <- "Mean"

df_melted = melt(high.scaled, id.vars = c('UniqueID', 'threshold'))
avail.high <- ggplot(df_melted, aes(x = variable, y = value)) + geom_line(aes(color = threshold, group = UniqueID)) + scale_color_manual(values = c("#f22116", "#000000")) +
  theme(axis.text.x=element_text(angle = 90))

low.scaled <- metric.list.NextSeq.scaled[metric.list.NextSeq.scaled$threshold == "Low",]
a <- as.vector(apply(low.scaled[-c(1,20)], 2, mean))



low.scaled[nrow(low.scaled) + 1,][-c(1,20)] <- a
low.scaled[nrow(low.scaled),][,1] <- 9999
low.scaled[nrow(low.scaled),][,20] <- "Mean"

df_melted = melt(low.scaled, id.vars = c('UniqueID', 'threshold'))
avail.low <- ggplot(df_melted, aes(x = variable, y = value)) + geom_line(aes(color = threshold, group = UniqueID)) + scale_color_manual(values = c("#16f2b7", "#000000")) + 
  theme(axis.text.x=element_text(angle = 90))


normal.scaled <- metric.list.NextSeq.scaled[metric.list.NextSeq.scaled$threshold == "Norm",]
a <- as.vector(apply(normal.scaled[-c(1,20)], 2, mean))

normal.scaled[nrow(normal.scaled) + 1,][-c(1,20)] <- a
normal.scaled[nrow(normal.scaled),][,1] <- 9999
normal.scaled[nrow(normal.scaled),][,20] <- "Mean"
normal.scaled
df_melted = melt(normal.scaled, id.vars = c('UniqueID', 'threshold'))
avail.Normal <- ggplot(df_melted, aes(x = variable, y = value)) + geom_line(aes(color = threshold, group = UniqueID)) + scale_color_manual(values = c("#49f216", "#000000")) + 
  theme(axis.text.x=element_text(angle = 90))

avail.high
avail.Normal
avail.low

high <- high.scaled[high.scaled$threshold == "Mean",]
low <- low.scaled[low.scaled$threshold == "Mean",]
normal <- normal.scaled[normal.scaled$threshold == "Mean",]
high$threshold <- "High"
high$UniqueID <- 1
low$threshold <- "Low"
low$UniqueID <- 2
normal$threshold <- "Normal"
normal$UniqueID <- 3


df <- high
df[2,] <- low
df[3,] <- normal

df
df_melted = melt(df, id.vars = c('UniqueID', 'threshold'))
mean.lines <- ggplot(df_melted, aes(x = variable, y = value)) + geom_line(aes(color = threshold, group = UniqueID)) + scale_color_manual(values = c("#f22116", "#16f2b7", "#49f216")) + 
  theme(axis.text.x=element_text(angle = 90))

mean.lines

```
* Intensity seems to differ
* Prephasing seems to differ
* Mismatch rate seems to differ
* Median target coverage seems to differ
* Mean insert Size seems to differ
* Number of aligned reads seem to differ
* Fraction of duplicates seem to differ


### Tests For intensity
```{r}
normal <- metric.list.NextSeq[metric.list.NextSeq$threshold == "Norm",]
high <- metric.list.NextSeq[metric.list.NextSeq$threshold == "High",]
t <-t.test(normal$Intensity, high$Intensity, paired = F)

t

difference <- mean(normal$Intensity) - mean(high$Intensity)
difference
```
Exeeding a higher threshold of 2.0 on the 260:280 ratio does not significantly change the sequencing intensity of NextSeq machines

```{r}
low <- metric.list.NextSeq[metric.list.NextSeq$threshold == "Low",]
normal <- metric.list.NextSeq[metric.list.NextSeq$threshold == "Norm",]

t <-t.test(normal$Intensity, low$Intensity, paired = F)


t

difference <- mean(normal$Intensity) - mean(low$Intensity)
difference
```
Exceeding the lower threshold of 1.8 significantly lowers the sequencing intensity in NextSeq machines, on average by 916, with a p-value of 0.029 

### Tests for PrePhasing
```{r}
normal <- metric.list.NextSeq[metric.list.NextSeq$threshold == "Norm",]
high <- metric.list.NextSeq[metric.list.NextSeq$threshold == "High",]
t <-t.test(normal$PrePhasing, high$PrePhasing, paired = F)

t

difference <- mean(normal$PrePhasing) - mean(high$PrePhasing)
difference
```
Exeeding a higher threshold of 2.0 on the 260:280 ratio does not significantly change the Prephasing precentage of NextSeq machines

```{r}
low <- metric.list.NextSeq[metric.list.NextSeq$threshold == "Low",]
normal <- metric.list.NextSeq[metric.list.NextSeq$threshold == "Norm",]

t <-t.test(normal$PrePhasing, low$PrePhasing, paired = F)


t

difference <- mean(normal$PrePhasing) - mean(low$PrePhasing)
difference
```
Exceeding the lower threshold of 1.8 does not alter the prephasing percentage in NextSeq machines, with a p-value of 0.054 > 0.05.

### Tests for Mismatch rate

```{r}
normal <- metric.list.NextSeq[metric.list.NextSeq$threshold == "Norm",]
high <- metric.list.NextSeq[metric.list.NextSeq$threshold == "High",]
t <-t.test(normal$PFmismatchRate, high$PFmismatchRate, paired = F)

t

difference <- mean(normal$PFmismatchRate) - mean(high$PFmismatchRate)
difference
```
Exeeding a higher threshold of 2.0 on the 260:280 ratio does not significantly change the mismatch rate in NextSeq machines with a p-value = 0.83 > 0.05

```{r}
low <- metric.list.NextSeq[metric.list.NextSeq$threshold == "Low",]
normal <- metric.list.NextSeq[metric.list.NextSeq$threshold == "Norm",]

t <-t.test(normal$PFmismatchRate, low$PFmismatchRate, paired = F)


t

difference <- mean(normal$PFmismatchRate) - mean(low$PFmismatchRate)
difference
```
Exceeding the lower threshold of 1.8 does significantly lowers the mismatch Rate slightly by 0.13 % in NextSeq machines, with a p-value of 1.79e-14 < 0.05.

### Tests for Median target coverage
```{r}
normal <- metric.list.NextSeq[metric.list.NextSeq$threshold == "Norm",]
high <- metric.list.NextSeq[metric.list.NextSeq$threshold == "High",]
t <-t.test(normal$MedianTargetCoverage, high$MedianTargetCoverage, paired = F)

t

difference <- mean(normal$MedianTargetCoverage) - mean(high$MedianTargetCoverage)
difference
```
Exeeding a higher threshold of 2.0 on the 260:280 ratio significantly increases the MedianTargetCoverage on average by 25 on NextSeq machines, with p-value of 0.0016 < 0.05. 

```{r}
low <- metric.list.NextSeq[metric.list.NextSeq$threshold == "Low",]
normal <- metric.list.NextSeq[metric.list.NextSeq$threshold == "Norm",]

t <-t.test(normal$MedianTargetCoverage, low$MedianTargetCoverage, paired = F)


t

difference <- mean(normal$MedianTargetCoverage) - mean(low$MedianTargetCoverage)
difference
```
Exceeding the lower threshold of 1.8 does significantly the Median Target Coverage in NextSeq machines, with a p-value of < 2.2e-16. 
I doubt that this is correct, while yes significance exists, you would not expect the target coverage to increase with a lower quality sample. I suspect there are more factors at play for the target coverage.

### Tests for Mean insert Size 

```{r}
normal <- metric.list.NextSeq[metric.list.NextSeq$threshold == "Norm",]
high <- metric.list.NextSeq[metric.list.NextSeq$threshold == "High",]
t <-t.test(normal$MeanSize, high$MeanSize, paired = F)

t

difference <- mean(normal$MeanSize) - mean(high$MeanSize)
difference
```
Exceeding the higher threshold of 2.0 significantly impacts the mean insert size, on average by 10.5, with a p-value of 0.006 < 0.05

```{r}
low <- metric.list.NextSeq[metric.list.NextSeq$threshold == "Low",]
normal <- metric.list.NextSeq[metric.list.NextSeq$threshold == "Norm",]

t <-t.test(normal$MeanSize, low$MeanSize, paired = F)


t

difference <- mean(normal$MeanSize) - mean(low$MeanSize)
difference
```
Exceeding the lower threshold of 1.8 does  alter the mean insert size, on average by 19.8 in NextSeq machines, with a p-value of < 2.2e-16. My recommendation however is to not lower your sample purity for a higher insert size.

### aligned reads Tests

```{r}
normal <- metric.list.NextSeq[metric.list.NextSeq$threshold == "Norm",]
high <- metric.list.NextSeq[metric.list.NextSeq$threshold == "High",]
t <-t.test(normal$PFUQaligned, high$PFUQaligned, paired = F)

t

difference <- mean(normal$PFUQaligned) - mean(high$PFUQaligned)
difference
```
Exeeding a higher threshold of 2.0 on the 260:280 ratio does not significantly change the number of aligned reads in NextSeq machines

```{r}
low <- metric.list.NextSeq[metric.list.NextSeq$threshold == "Low",]
normal <- metric.list.NextSeq[metric.list.NextSeq$threshold == "Norm",]

t <-t.test(normal$PFUQaligned, low$PFUQaligned, paired = F)


t

difference <- mean(normal$PFUQaligned) - mean(low$PFUQaligned)
difference
```
Exceeding the lower threshold of 1.8 significantly lowers the number of aligned reads by 23805717 on average, with a p-value of 2.365e-15 < 0.05

### Tests For Duplicates

```{r}
normal <- metric.list.NextSeq[metric.list.NextSeq$threshold == "Norm",]
high <- metric.list.NextSeq[metric.list.NextSeq$threshold == "High",]
t <-t.test(normal$PrePhasing, high$PrePhasing, paired = F)

t

difference <- mean(normal$FractionDuplicates) - mean(high$FractionDuplicates)
difference
```
Exeeding a higher threshold of 2.0 on the 260:280 ratio does not significantly change the number of duplicates in NextSeq machines

```{r}
low <- metric.list.NextSeq[metric.list.NextSeq$threshold == "Low",]
normal <- metric.list.NextSeq[metric.list.NextSeq$threshold == "Norm",]

t <-t.test(normal$FractionDuplicates, low$FractionDuplicates, paired = F)


t

difference <- mean(normal$FractionDuplicates) - mean(low$FractionDuplicates)
difference
```
Exceeding the lower threshold of 1.8 significantly increases the number of duplicates, on average by 2.3 %, with a p-value of 0.007158 < 0.05


```{r}
metric.list.MiSeq.scaled <- as.data.frame(apply(metric.list.NextSeq, 2, range02))
metric.list.MiSeq.scaled$threshold <- unlist(lapply(metric.list.NextSeq$A260_280, function(x) {
  val <- x
  if (val > 2.0) {
    return("High")
  }
  if (val < 1.8) {
    return("Low")
  }
  return("Normal")
}))
metric.list.MiSeq.scaled$UniqueID <- metric.list.NextSeq$UniqueID

df_melted = melt(metric.list.MiSeq.scaled[metric.list.MiSeq.scaled$threshold == "High",], id.vars = c('UniqueID', 'threshold'))
avail.high <- ggplot(df_melted, aes(x = variable, y = value)) + geom_line(aes(color = threshold, group = UniqueID)) + scale_color_manual(values = c("#f22116", "#16f2b7", "#49f216", "#165ff2")) +
  theme(axis.text.x=element_text(angle = 90))

df_melted = melt(metric.list.MiSeq.scaled[metric.list.MiSeq.scaled$threshold == "Low",], id.vars = c('UniqueID', 'threshold'))
avail.low <- ggplot(df_melted, aes(x = variable, y = value)) + geom_line(aes(color = threshold, group = UniqueID)) + scale_color_manual(values = c("#16f2b7")) + 
  theme(axis.text.x=element_text(angle = 90))



df_melted = melt(metric.list.MiSeq.scaled[metric.list.MiSeq.scaled$threshold == "Normal",], id.vars = c('UniqueID', 'threshold'))
avail.Normal <- ggplot(df_melted, aes(x = variable, y = value)) + geom_line(aes(color = threshold, group = UniqueID)) + scale_color_manual(values = c("#49f216")) + 
  theme(axis.text.x=element_text(angle = 90))

avail.high
avail.Normal
avail.low
```

## MiSeq Machines

```{r}
metric.list.MiSeq.scaled <- as.data.frame(apply(metric.list.MiSeq, 2, range02))

metric.list.MiSeq$threshold <- unlist(lapply(metric.list.MiSeq$A260_280, function(x) {
  val <- x
  if (val > 2.0) {
    return("High")
  }
  if (val < 1.8) {
    return("Low")
  }
  return("Norm")
}))

metric.list.MiSeq.scaled$threshold <- unlist(lapply(metric.list.MiSeq$A260_280, function(x) {
  val <- x
  if (val > 2.0) {
    return("High")
  }
  if (val < 1.8) {
    return("Low")
  }
  return("Norm")
}))

metric.list.MiSeq.scaled$UniqueID <- metric.list.MiSeq$UniqueID
high.scaled <- metric.list.MiSeq.scaled[metric.list.MiSeq.scaled$threshold == "High",]


a <- as.vector(apply(high.scaled[-c(1,20)], 2, mean))



high.scaled[nrow(high.scaled) + 1,][-c(1,20)] <- a
high.scaled[nrow(high.scaled),][,1] <- 9999
high.scaled[nrow(high.scaled),][,20] <- "Mean"

df_melted = melt(high.scaled, id.vars = c('UniqueID', 'threshold'))
avail.high <- ggplot(df_melted, aes(x = variable, y = value)) + geom_line(aes(color = threshold, group = UniqueID)) + scale_color_manual(values = c("#f22116", "#000000")) +
  theme(axis.text.x=element_text(angle = 90))

low.scaled <- metric.list.MiSeq.scaled[metric.list.MiSeq.scaled$threshold == "Low",]
a <- as.vector(apply(low.scaled[-c(1,20)], 2, mean))



low.scaled[nrow(low.scaled) + 1,][-c(1,20)] <- a
low.scaled[nrow(low.scaled),][,1] <- 9999
low.scaled[nrow(low.scaled),][,20] <- "Mean"

df_melted = melt(low.scaled, id.vars = c('UniqueID', 'threshold'))
avail.low <- ggplot(df_melted, aes(x = variable, y = value)) + geom_line(aes(color = threshold, group = UniqueID)) + scale_color_manual(values = c("#16f2b7", "#000000")) + 
  theme(axis.text.x=element_text(angle = 90))


normal.scaled <- metric.list.MiSeq.scaled[metric.list.MiSeq.scaled$threshold == "Norm",]
a <- as.vector(apply(normal.scaled[-c(1,20)], 2, mean))

normal.scaled[nrow(normal.scaled) + 1,][-c(1,20)] <- a
normal.scaled[nrow(normal.scaled),][,1] <- 9999
normal.scaled[nrow(normal.scaled),][,20] <- "Mean"
normal.scaled
df_melted = melt(normal.scaled, id.vars = c('UniqueID', 'threshold'))
avail.Normal <- ggplot(df_melted, aes(x = variable, y = value)) + geom_line(aes(color = threshold, group = UniqueID)) + scale_color_manual(values = c("#49f216", "#000000")) + 
  theme(axis.text.x=element_text(angle = 90))

avail.high
avail.Normal
avail.low

high <- high.scaled[high.scaled$threshold == "Mean",]
low <- low.scaled[low.scaled$threshold == "Mean",]
normal <- normal.scaled[normal.scaled$threshold == "Mean",]
high$threshold <- "High"
high$UniqueID <- 1
low$threshold <- "Low"
low$UniqueID <- 2
normal$threshold <- "Normal"
normal$UniqueID <- 3


df <- high
df[2,] <- low
df[3,] <- normal

df
df_melted = melt(df, id.vars = c('UniqueID', 'threshold'))
mean.lines <- ggplot(df_melted, aes(x = variable, y = value)) + geom_line(aes(color = threshold, group = UniqueID)) + scale_color_manual(values = c("#f22116", "#16f2b7", "#49f216")) + 
  theme(axis.text.x=element_text(angle = 90))

mean.lines

```
